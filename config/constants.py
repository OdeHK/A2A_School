# config/constants.py
"""
ƒê·ªãnh nghƒ©a c√°c h·∫±ng s·ªë ƒë∆∞·ª£c s·ª≠ d·ª•ng trong to√†n b·ªô ·ª©ng d·ª•ng.
T√°ch ri√™ng constants ra kh·ªèi settings ƒë·ªÉ d·ªÖ qu·∫£n l√Ω.
"""

from typing import Dict, List


class ModelConstants:
    """H·∫±ng s·ªë li√™n quan ƒë·∫øn c√°c model AI"""
    
    # === LLM Provider mappings ===
    SUPPORTED_LLM_PROVIDERS = {
        "nvidia": "NVIDIA NIM inference services",
        "google_gen_ai": "Google Generative AI"

    }
    
    DEFAULT_LLM_PROVIDER = "nvidia"

    # === Default models cho t·ª´ng provider ===
    DEFAULT_MODELS = {
        "nvidia": "openai/gpt-oss-20b",
        "google_gen_ai": "models/gemini-2.5-flash-lite",
    }
    
    # === Embedding models ===
    EMBEDDING_MODELS = {
        "nvidia": "nvidia/llama-3.2-nemoretriever-300m-embed-v1",
        "google_gen_ai": "models/gemini-embedding-001",
        "huggingface": "Alibaba-NLP/gte-multilingual-base"
    }
    
    HUGGINGFACE_CACHE_DIR = "./.cache/huggingface"

    # === Model limitations ===
    MAX_CONTEXT_LENGTHS = {
        "openai/gpt-oss-20b": 128000
    }
    
    
    # === Temperature ranges ===
    MIN_TEMPERATURE = 0.0
    MAX_TEMPERATURE = 2.0
    DEFAULT_TEMPERATURE = 0.2
    
    # === Token limits ===
    DEFAULT_MAX_TOKENS = 4096
    MIN_MAX_TOKENS = 100
    MAX_MAX_TOKENS = 8192


class UIConstants:
    """H·∫±ng s·ªë li√™n quan ƒë·∫øn giao di·ªán ng∆∞·ªùi d√πng"""
    
    # === App metadata ===
    APP_NAME = "AI Teacher Assistant"
    APP_VERSION = "1.0.0"
    APP_DESCRIPTION = "Tr·ª£ l√Ω AI th√¥ng minh cho gi√°o vi√™n"
    
    # === UI Messages ===
    MESSAGES = {
        "welcome": "Ch√†o m·ª´ng ƒë·∫øn v·ªõi AI Teacher Assistant! üëã",
        "api_key_required": "‚ö†Ô∏è Vui l√≤ng cung c·∫•p API key ƒë·ªÉ s·ª≠ d·ª•ng.",
        "llm_initialized": "‚úÖ LLM ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng!",
        "file_uploaded": "‚úÖ File ƒë√£ ƒë∆∞·ª£c upload v√† x·ª≠ l√Ω th√†nh c√¥ng!",
        "error_occurred": "‚ùå C√≥ l·ªói x·∫£y ra: {error}",
        "processing": "üîÑ ƒêang x·ª≠ l√Ω...",
        "no_documents": "üìÑ Ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c upload.",
        "session_started": "üöÄ Phi√™n l√†m vi·ªác m·ªõi ƒë√£ ƒë∆∞·ª£c t·∫°o!"
    }
    
    # === UI Components ===
    SIDEBAR_WIDTH = 300
    CHAT_HEIGHT = 600
    MAX_CHAT_HISTORY = 50
    
    # === File upload constraints ===
    MAX_FILE_SIZE_MB = 50
    MAX_FILES_PER_UPLOAD = 10
    
    # === Gradio theme colors ===
    THEME_COLORS = {
        "primary": "#2563eb",
        "secondary": "#64748b", 
        "success": "#059669",
        "warning": "#d97706",
        "error": "#dc2626"
    }


class FileConstants:
    """H·∫±ng s·ªë li√™n quan ƒë·∫øn x·ª≠ l√Ω file"""
    
    # === Supported file formats ===
    SUPPORTED_DOCUMENT_TYPES = {
        ".pdf": "PDF Document",
    }
    
    # === File type categorization ===
    TEXT_FILES = [".txt", ".md", ".csv", ".json"]
    DOCUMENT_FILES = [".pdf", ".docx", ".doc", ".pptx"]  
    SPREADSHEET_FILES = [".csv", ".xlsx"]
    WEB_FILES = [".html", ".htm"]
    
    # === MIME types ===
    MIME_TYPES = {
        ".pdf": "application/pdf",
        ".txt": "text/plain",
        ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        ".csv": "text/csv",
        ".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        ".json": "application/json",
        ".html": "text/html"
    }
    
    # === Chunking strategies ===
    CHUNKING_STRATEGIES = {
        "ONE_PAGE": "M·ªôt chunk per trang",
        "RECURSIVE": "Chia nh·ªè ƒë·ªá quy theo k√Ω t·ª±",
        "LLM": "S·ª≠ d·ª•ng LLM ph√¢n chia c√°c ƒëo·∫°n vƒÉn v√† ti·ªÅn x·ª≠ l√Ω",
    }
    
    # === Default chunk settings ===
    DEFAULT_CHUNK_SIZE = 1000
    DEFAULT_CHUNK_OVERLAP = 200
    MIN_CHUNK_SIZE = 100
    MAX_CHUNK_SIZE = 4000
    
    # === File size limits (in bytes) ===
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    MAX_TOTAL_SIZE = 500 * 1024 * 1024  # 500MB total


# === Document Repository folder names ===
class DocumentRepositoryConstants:
    """H·∫±ng s·ªë li√™n quan ƒë·∫øn c√°c folder trong DocumentRepository"""
    BASE_DOCUMENTS_DIR = "session_data"
    SESSIONS_DIR = "sessions"
    TEMP_DIR = "temp"
    RAW_FILES_DIR = "raw_files"
    METADATA_DIR = "metadata"
    TOC_DIR = "toc"
    CONTENT_DIR = "content"  # Th√™m th∆∞ m·ª•c cho content data t·ª´ toc_extractor
    DOCUMENT_LIBRARY_DIR = "document_library"  # Th√™m th∆∞ m·ª•c cho document library
    VECTOR_STORE_DIR = "vector_store"


class AgentConstants:
    """H·∫±ng s·ªë li√™n quan ƒë·∫øn AI Agents"""
    
    # === Agent types ===
    # AGENT_TYPES = {
    #     "main": "Main Teacher Agent",
    #     "exam_creator": "Exam Creation Agent", 
    #     "document_analyzer": "Document Analysis Agent",
    #     "classroom_manager": "Classroom Management Agent",
    #     "lesson_planner": "Lesson Planning Agent"
    # }
    
    # # === Agent capabilities ===
    # AGENT_CAPABILITIES = {
    #     "exam_creator": [
    #         "T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám",
    #         "T·∫°o c√¢u h·ªèi t·ª± lu·∫≠n", 
    #         "Ph√¢n lo·∫°i ƒë·ªô kh√≥",
    #         "Export ƒë·ªÅ thi ra Google Forms"
    #     ],
    #     "document_analyzer": [
    #         "T√≥m t·∫Øt t√†i li·ªáu",
    #         "Tr√≠ch xu·∫•t ƒëi·ªÉm ch√≠nh",
    #         "Ph√¢n t√≠ch n·ªôi dung",
    #         "So s√°nh t√†i li·ªáu"
    #     ],
    #     "classroom_manager": [
    #         "Qu·∫£n l√Ω Google Classroom",
    #         "T·∫°o assignment",
    #         "Theo d√µi progress",
    #         "G·ª≠i th√¥ng b√°o"
    #     ]
    # }
    
    # # === Tool categories ===
    # TOOL_CATEGORIES = {
    #     "document": "Document Processing Tools",
    #     "google": "Google Services Tools", 
    #     "exam": "Exam Creation Tools",
    #     "analysis": "Analysis Tools",
    #     "utility": "Utility Tools"
    # }
    
    # # === Default agent prompts ===
    # DEFAULT_SYSTEM_PROMPTS = {
    #     "main": """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh cho gi√°o vi√™n. 
    #     B·∫°n c√≥ th·ªÉ gi√∫p t·∫°o ƒë·ªÅ thi, ph√¢n t√≠ch t√†i li·ªáu, qu·∫£n l√Ω l·ªõp h·ªçc v√† h·ªó tr·ª£ gi·∫£ng d·∫°y.
    #     H√£y s·ª≠ d·ª•ng c√°c c√¥ng c·ª• c√≥ s·∫µn ƒë·ªÉ gi√∫p ƒë·ª° gi√°o vi√™n m·ªôt c√°ch hi·ªáu qu·∫£ nh·∫•t.""",
        
    #     "exam_creator": """B·∫°n l√† chuy√™n gia t·∫°o ƒë·ªÅ thi v√† c√¢u h·ªèi.
    #     Nhi·ªám v·ª• c·ªßa b·∫°n l√† t·∫°o ra c√°c c√¢u h·ªèi ch·∫•t l∆∞·ª£ng cao, ph√π h·ª£p v·ªõi n·ªôi dung h·ªçc t·∫≠p.""",
        
    #     "document_analyzer": """B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√†i li·ªáu gi√°o d·ª•c.
    #     H√£y gi√∫p gi√°o vi√™n hi·ªÉu r√µ n·ªôi dung, tr√≠ch xu·∫•t th√¥ng tin quan tr·ªçng v√† t√≥m t·∫Øt hi·ªáu qu·∫£."""
    # }


class DatabaseConstants:
    """H·∫±ng s·ªë li√™n quan ƒë·∫øn database v√† storage"""
    
    # === Vector store configurations ===
    VECTOR_STORE_CONFIGS = {
        "chroma": {
            "persist_directory": "./vector_db/chroma",
            "collection_name": "teacher_documents"
        },
        "faiss": {
            "index_path": "./vector_db/faiss/index.faiss",
            "metadata_path": "./vector_db/faiss/metadata.json"
        }
    }


# === Global configuration mappings ===
def get_supported_file_extensions() -> List[str]:
    """L·∫•y danh s√°ch extension ƒë∆∞·ª£c h·ªó tr·ª£"""
    return list(FileConstants.SUPPORTED_DOCUMENT_TYPES.keys())


def get_llm_providers() -> List[str]:
    """L·∫•y danh s√°ch LLM providers ƒë∆∞·ª£c h·ªó tr·ª£"""
    return list(ModelConstants.SUPPORTED_LLM_PROVIDERS.keys())


def get_chunking_strategies() -> List[str]:
    """L·∫•y danh s√°ch chunking strategies"""
    return list(FileConstants.CHUNKING_STRATEGIES.keys())


def get_agent_types() -> List[str]:
    """L·∫•y danh s√°ch agent types"""
    return list(AgentConstants.AGENT_TYPES.keys())
