# backend_main.py

from fastapi import FastAPI, UploadFile, File, HTTPException
from pydantic import BaseModel
import uvicorn
from io import BytesIO
import os
import traceback
from dotenv import load_dotenv # <-- 1. Import thÆ° viá»‡n dotenv
from src.analysis_agent import AnalysisAgent # <-- ThÃªm import
from pydantic import BaseModel
# --- 2. Náº¡p cÃ¡c biáº¿n mÃ´i trÆ°á»ng tá»« file .env ---
# Lá»‡nh nÃ y pháº£i Ä‘Æ°á»£c gá»i trÆ°á»›c khi truy cáº­p os.environ
load_dotenv()
# ---------------------------------------------

# Import cÃ¡c module cá»§a báº¡n tá»« thÆ° má»¥c src
from src.document_reader import DocumentReader
from src.rag import RAGManager
from src.sentence_transformer_embedder import SentenceTransformerEmbedder
from src.openrouter_llm import OpenRouterLLM
from src import database_manager
import json
from langchain_text_splitters import RecursiveCharacterTextSplitter

# --- Khá»Ÿi táº¡o á»©ng dá»¥ng FastAPI ---
app = FastAPI(title="AI Backend Service")

# --- Khá»Ÿi táº¡o cÃ¡c Ä‘á»‘i tÆ°á»£ng AI (Singleton Pattern) ---
@app.on_event("startup")
async def startup_event():
    """HÃ m nÃ y sáº½ cháº¡y má»™t láº§n duy nháº¥t khi server báº¯t Ä‘áº§u."""
    global document_reader, rag_manager, analysis_agent, llm, embedder
    
    try:
        # Load vÃ  validate environment variables
        model_name = os.getenv("OPENROUTER_MODEL")
        api_key = os.getenv("OPENROUTER_API_KEY")
        
        if not api_key:
            raise ValueError("OPENROUTER_API_KEY khÃ´ng Ä‘Æ°á»£c cáº¥u hÃ¬nh trong file .env")
        if not model_name:
            model_name = "openai/gpt-oss-20b:free"  # Fallback to a stable model
            print(f"âš ï¸ OPENROUTER_MODEL khÃ´ng Ä‘Æ°á»£c cáº¥u hÃ¬nh, sá»­ dá»¥ng model máº·c Ä‘á»‹nh: {model_name}")
        
        # Validate grades.csv exists
        grades_path = os.path.join(os.path.dirname(__file__), 'data', 'grades.csv')
        if not os.path.exists(grades_path):
            raise FileNotFoundError(f"File grades.csv khÃ´ng tá»“n táº¡i táº¡i: {grades_path}")
        
        # Initialize components with better error handling
        print("ðŸ”„ Äang khá»Ÿi táº¡o OpenRouter LLM...")
        llm = OpenRouterLLM(model_name=model_name, api_key=api_key)
        
        print("ðŸ”„ Äang khá»Ÿi táº¡o Sentence Transformer...")
        embedder = SentenceTransformerEmbedder()
        
        print("ðŸ”„ Äang khá»Ÿi táº¡o Document Reader...")
        document_reader = DocumentReader()
        
        # Test OpenRouter connection
        test_prompt = "This is a test message. Reply with 'OK' if you receive this."
        try:
            response = llm.invoke(test_prompt)
            print("âœ… Káº¿t ná»‘i OpenRouter API thÃ nh cÃ´ng!")
        except Exception as e:
            print(f"âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng thá»ƒ káº¿t ná»‘i Ä‘áº¿n OpenRouter API: {str(e)}")
            print("âš ï¸ Há»‡ thá»‘ng sáº½ tiáº¿p tá»¥c khá»Ÿi Ä‘á»™ng nhÆ°ng cÃ¡c chá»©c nÄƒng LLM cÃ³ thá»ƒ khÃ´ng hoáº¡t Ä‘á»™ng.")
        
        # Initialize other components
        chunker = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
            is_separator_regex=False,
        )
        
        print("ðŸ”„ Äang khá»Ÿi táº¡o RAG Manager...")
        rag_manager = RAGManager(chunker=chunker, llm=llm, embedder=embedder)
        
        print("ðŸ”„ Äang khá»Ÿi táº¡o Analysis Agent...")
        analysis_agent = AnalysisAgent(data_path=grades_path)
        
        print("âœ… Khá»Ÿi táº¡o há»‡ thá»‘ng thÃ nh cÃ´ng!")
        
    except Exception as e:
        print(f"âŒ Lá»—i khi khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng: {str(e)}")
        raise
    
    # Initialize text splitter for chunking
    chunker = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
        is_separator_regex=False,
    )
    
    # Initialize RAG manager with all required components
    rag_manager = RAGManager(chunker=chunker, llm=llm, embedder=embedder)
    
    # Initialize Analysis Agent with absolute path
    grades_path = os.path.join(os.path.dirname(__file__), 'data', 'grades.csv')
    analysis_agent = AnalysisAgent(data_path=grades_path)
    
    # Verify DataFrame is loaded correctly
    if analysis_agent.df.empty:
        raise ValueError("Grades data is empty")
    if 'subject' not in analysis_agent.df.columns:
        raise ValueError(f"Required column 'subject' not found. Available columns: {', '.join(analysis_agent.df.columns)}")
    
    print("âœ… Agent PhÃ¢n tÃ­ch Ä‘Ã£ sáºµn sÃ ng.")
    
    database_manager.create_tables()
    print("âœ… Backend service Ä‘Ã£ sáºµn sÃ ng.")

# --- Endpoint Má»›i cho Agent GiÃ¡o viÃªn ---
class SuggestionRequest(BaseModel):
    subject: str
    lesson_topic: str

@app.post("/teacher/generate-suggestions/")
async def handle_teaching_suggestions(request: SuggestionRequest):
    """
    Endpoint A2A: Láº¥y dá»¯ liá»‡u tá»« Agent PhÃ¢n tÃ­ch, sau Ä‘Ã³ dÃ¹ng LLM Ä‘á»ƒ táº¡o gá»£i Ã½.
    """
    # 1. Gá»i Agent PhÃ¢n tÃ­ch Ä‘á»ƒ láº¥y dá»¯ liá»‡u
    class_overview = analysis_agent.get_class_overview(request.subject)
    student_groups = analysis_agent.group_students_by_level(request.subject)

    if not class_overview or not student_groups:
        raise HTTPException(status_code=404, detail=f"KhÃ´ng cÃ³ dá»¯ liá»‡u cho mÃ´n há»c {request.subject}")

    # 2. XÃ¢y dá»±ng prompt cho LLM
    suggestion_prompt = f"""
    Báº N LÃ€ Má»˜T CHUYÃŠN GIA TÆ¯ Váº¤N SÆ¯ PHáº M.
    Dá»±a vÃ o dá»¯ liá»‡u phÃ¢n tÃ­ch há»c lá»±c cá»§a lá»›p vÃ  chá»§ Ä‘á» bÃ i há»c, hÃ£y Ä‘Æ°a ra Ä‘á» xuáº¥t chi tiáº¿t cho giÃ¡o viÃªn.

    **Chá»§ Ä‘á» bÃ i há»c sáº¯p tá»›i:** {request.lesson_topic}
    **MÃ´n há»c:** {request.subject}

    **Dá»¯ liá»‡u PhÃ¢n tÃ­ch:**
    - Thá»‘ng kÃª chung cá»§a lá»›p: {json.dumps(class_overview, indent=2, ensure_ascii=False)}
    - PhÃ¢n nhÃ³m há»c sinh theo trÃ¬nh Ä‘á»™: {json.dumps(student_groups, indent=2, ensure_ascii=False)}

    **YÃªu cáº§u:**
    1.  **Gá»£i Ã½ cÃ¡ch chia nhÃ³m:** Äá» xuáº¥t cÃ¡ch chia nhÃ³m vÃ  hoáº¡t Ä‘á»™ng phÃ¹ há»£p cho tá»«ng nhÃ³m (Giá»i, KhÃ¡, Trung bÃ¬nh, Yáº¿u).
    2.  **Äá» xuáº¥t phÆ°Æ¡ng phÃ¡p dáº¡y:** Gá»£i Ã½ 2-3 phÆ°Æ¡ng phÃ¡p giáº£ng dáº¡y cá»¥ thá»ƒ cho chá»§ Ä‘á» "{request.lesson_topic}".
    3.  **Äá» xuáº¥t tÃ i liá»‡u giáº£ng dáº¡y:** Gá»£i Ã½ cÃ¡c loáº¡i tÃ i liá»‡u bá»• sung mÃ  giÃ¡o viÃªn nÃªn chuáº©n bá»‹.

    HÃ£y trÃ¬nh bÃ y má»™t cÃ¡ch rÃµ rÃ ng vÃ  cÃ³ tÃ­nh hÃ nh Ä‘á»™ng cao.
    """
    
    # 3. Gá»i LLM vÃ  tráº£ vá» káº¿t quáº£
    try:
        suggestion = rag_manager.llm.invoke(suggestion_prompt)
        return {"suggestion": suggestion}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
# --- CÃ¡c API Endpoint (Giá»¯ nguyÃªn) ---
@app.post("/process-document/")
async def process_document(file: UploadFile = File(...)):
    try:
        file_bytes = BytesIO(await file.read())
        filetype = file.filename.split('.')[-1].lower()
        document_text = document_reader.read(file_bytes, filetype)
        if not document_text:
            raise HTTPException(status_code=400, detail="KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung file.")
        rag_manager.setup_with_text(document_text)
        return {"status": "success", "filename": file.filename, "message": "TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½."}
    except Exception as e:
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

class QueryRequest(BaseModel):
    question: str

@app.post("/query/")
async def handle_query(request: QueryRequest):
    if not rag_manager.retriever:
        raise HTTPException(status_code=400, detail="ChÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c xá»­ lÃ½.")
    answer = rag_manager.query(request.question)
    return {"answer": answer}

class QuizRequest(BaseModel):
    num_questions: int = 5
    subject: str = "Quiz chung"

@app.post("/generate-quiz/")
async def handle_quiz_generation(request: QuizRequest):
    try:
        if not rag_manager.retriever:
            raise HTTPException(
                status_code=400, 
                detail="Vui lÃ²ng táº£i lÃªn vÃ  xá»­ lÃ½ tÃ i liá»‡u trÆ°á»›c khi táº¡o quiz."
            )
            
        quiz_data = rag_manager.generate_quiz(request.num_questions)
        
        if not quiz_data:
            raise HTTPException(
                status_code=500,
                detail="KhÃ´ng thá»ƒ táº¡o quiz. Vui lÃ²ng thá»­ láº¡i sau."
            )
            
        if not isinstance(quiz_data, list):
            raise HTTPException(
                status_code=500,
                detail=f"Äá»‹nh dáº¡ng quiz khÃ´ng há»£p lá»‡: {quiz_data}"
            )
            
        if len(quiz_data) == 0:
            raise HTTPException(
                status_code=500,
                detail="KhÃ´ng thá»ƒ táº¡o cÃ¢u há»i tá»« tÃ i liá»‡u nÃ y. Vui lÃ²ng thá»­ tÃ i liá»‡u khÃ¡c."
            )
            
        # Validate quiz format
        for i, question in enumerate(quiz_data):
            if not all(key in question for key in ['question', 'choices', 'correct_answer']):
                raise HTTPException(
                    status_code=500,
                    detail=f"CÃ¢u há»i {i+1} thiáº¿u thÃ´ng tin báº¯t buá»™c."
                )
        
        # Save quiz to database
        try:
            quiz_id = database_manager.save_quiz(quiz_data, subject=request.subject)
        except Exception as db_error:
            raise HTTPException(
                status_code=500,
                detail=f"Lá»—i khi lÆ°u quiz vÃ o database: {str(db_error)}"
            )
            
        return {
            "status": "success",
            "message": f"ÄÃ£ táº¡o thÃ nh cÃ´ng {len(quiz_data)} cÃ¢u há»i",
            "quiz_id": quiz_id,
            "quiz_data": quiz_data
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng mong muá»‘n khi táº¡o quiz: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail="ÄÃ£ xáº£y ra lá»—i khÃ´ng mong muá»‘n. Vui lÃ²ng thá»­ láº¡i sau."
        )
class ExpertChatRequest(BaseModel):
    question: str
    chat_history: list = []

@app.post("/student/expert-chat/")
async def handle_expert_chat(request: ExpertChatRequest):
    if not rag_manager.retriever:
        raise HTTPException(status_code=400, detail="ChÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c xá»­ lÃ½.")
    answer = rag_manager.act_as_expert(request.question, request.chat_history)
    return {"answer": answer}

@app.get("/teacher/class-overview/{subject}")
async def get_class_overview(subject: str):
    """Endpoint Ä‘á»ƒ láº¥y thá»‘ng kÃª tá»•ng quan vá» lá»›p há»c."""
    class_data = analysis_agent.get_class_overview(subject)
    if not class_data:
        raise HTTPException(status_code=404, detail="KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u cho mÃ´n há»c nÃ y")
        
    distribution_data = analysis_agent.group_students_by_level(subject)
    return {
        "mean": class_data.get("mean", 0),
        "max": class_data.get("max", 0),
        "min": class_data.get("min", 0),
        "distribution": distribution_data
    }

class ResearchTopicRequest(BaseModel):
    num_topics: int = 3

@app.post("/student/suggest-topics/")
async def handle_research_topics(request: ResearchTopicRequest):
    if not rag_manager.retriever:
        raise HTTPException(status_code=400, detail="ChÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c xá»­ lÃ½.")
    topics = rag_manager.suggest_research_topics(request.num_topics)
    return {"topics": topics}
# --- Cháº¡y server ---
if __name__ == "__main__":
    uvicorn.run("backend_main:app", host="0.0.0.0", port=8000, reload=True)
