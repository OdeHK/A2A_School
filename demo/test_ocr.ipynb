{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a7f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\likgn\\anaconda3\\envs\\ai_python_3_10\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\likgn\\anaconda3\\envs\\ai_python_3_10\\lib\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\likgn\\anaconda3\\envs\\ai_python_3_10\\lib\\site-packages (from pytesseract) (11.3.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb7a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "# VÃ­ dá»¥ Windows: Ä‘Æ°á»ng dáº«n tá»›i tesseract.exe\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Users\\likgn\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e2026b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TesseractError",
     "evalue": "(1, 'Error opening data file C:\\\\Users\\\\likgn\\\\AppData\\\\Local\\\\Programs\\\\Tesseract-OCR/tessdata/equ.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'equ\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTesseractError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(pix\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# OCR vá»›i tiáº¿ng Viá»‡t: lang=\"vie\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     page_text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mequ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Trang \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpage_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# LÆ°u káº¿t quáº£\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\likgn\\anaconda3\\envs\\ai_python_3_10\\lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\likgn\\anaconda3\\envs\\ai_python_3_10\\lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    487\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[0;32m    488\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[1;32m--> 489\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    490\u001b[0m }[output_type]()\n",
      "File \u001b[1;32mc:\\Users\\likgn\\anaconda3\\envs\\ai_python_3_10\\lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    342\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    350\u001b[0m     }\n\u001b[1;32m--> 352\u001b[0m     run_tesseract(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    355\u001b[0m         return_bytes,\n\u001b[0;32m    356\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\likgn\\anaconda3\\envs\\ai_python_3_10\\lib\\site-packages\\pytesseract\\pytesseract.py:284\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[1;32m--> 284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractError(proc\u001b[38;5;241m.\u001b[39mreturncode, get_errors(error_string))\n",
      "\u001b[1;31mTesseractError\u001b[0m: (1, 'Error opening data file C:\\\\Users\\\\likgn\\\\AppData\\\\Local\\\\Programs\\\\Tesseract-OCR/tessdata/equ.traineddata Please make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory. Failed loading language \\'equ\\' Tesseract couldn\\'t load any languages! Could not initialize tesseract.')"
     ]
    }
   ],
   "source": [
    "import pymupdf  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Má»Ÿ file PDF\n",
    "pdf_path = r\"C:\\Users\\likgn\\Repository\\RAG\\documents\\one_page_latex_document.pdf\"\n",
    "doc = pymupdf.open(pdf_path)\n",
    "\n",
    "text = \"\"\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc[page_num]\n",
    "    # Xuáº¥t trang dÆ°á»›i dáº¡ng áº£nh (300dpi)\n",
    "    pix = page.get_pixmap(dpi=300)\n",
    "    img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "    \n",
    "    # OCR vá»›i tiáº¿ng Viá»‡t: lang=\"vie\"\n",
    "    page_text = pytesseract.image_to_string(img, lang=\"equ\")\n",
    "    text += f\"\\n--- Trang {page_num+1} ---\\n{page_text}\"\n",
    "\n",
    "# LÆ°u káº¿t quáº£\n",
    "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"HoÃ n táº¥t OCR vÃ  lÆ°u vÃ o output.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2a7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Iterator\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "class ChunkingStrategy(str, Enum):\n",
    "    \"\"\"Enum Ä‘á»‹nh nghÄ©a cÃ¡c chiáº¿n lÆ°á»£c chunking khÃ¡c nhau.\"\"\"\n",
    "    ONE_PAGE_PER_CHUNK = \"one_page_per_chunk\"  # Má»—i trang lÃ  má»™t chunk\n",
    "    RECURSIVE_SPLIT = \"recursive_character_split\"  # Sá»­ dá»¥ng RecursiveCharacterTextSplitter\n",
    "    LLM_SPLIT = \"llm_split\"\n",
    "\n",
    "class ThematicBlock(BaseModel):\n",
    "    \"\"\"Represents a single thematic block in the document\"\"\"\n",
    "    summary_title: str = Field(\n",
    "        description=\"The title of the thematic group. Don't add index numbers.\"\n",
    "    )\n",
    "    content: str = Field(\n",
    "        description=\"The extracted content of the thematic group.\"\n",
    "    )\n",
    "    start_page_index: int = Field(\n",
    "        default=0,\n",
    "        description=\"The starting page index of the thematic group.\"\n",
    "    )\n",
    "    end_page_index: int = Field(\n",
    "        default=0,\n",
    "        description=\"The ending page index of the thematic group.\"\n",
    "    )\n",
    "\n",
    "class ThematicGroupList(BaseModel):\n",
    "    \"\"\"A list of thematic blocks, each representing an extracted thematic block.\"\"\"\n",
    "    thematic_group_list: List[ThematicBlock] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of thematic blocks extracted from the document\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60d22ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! ðŸ‘‹ How can I help you today?', additional_kwargs={'reasoning_content': 'The user says \"hello\". We need to respond. The user hasn\\'t asked a question. We can respond with a friendly greeting. The user might want to start a conversation. We can ask how we can help. The user might want to talk about something. We can respond with a friendly greeting and ask what they need. There\\'s no special instructions. So we can respond with a friendly greeting.'}, response_metadata={'role': 'assistant', 'reasoning_content': 'The user says \"hello\". We need to respond. The user hasn\\'t asked a question. We can respond with a friendly greeting. The user might want to start a conversation. We can ask how we can help. The user might want to talk about something. We can respond with a friendly greeting and ask what they need. There\\'s no special instructions. So we can respond with a friendly greeting.', 'content': 'Hello! ðŸ‘‹ How can I help you today?', 'refusal': None, 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': [], 'token_usage': {'prompt_tokens': 68, 'total_tokens': 168, 'completion_tokens': 100, 'prompt_tokens_details': None}, 'finish_reason': 'stop', 'model_name': 'openai/gpt-oss-20b'}, id='run--baf1853c-865a-4cab-bc92-e358719eb0c1-0', usage_metadata={'input_tokens': 68, 'output_tokens': 100, 'total_tokens': 168}, role='assistant')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatNVIDIA(\n",
    "                    model=\"openai/gpt-oss-20b\",\n",
    "                    api_key=\"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\",\n",
    "                    temperature=0.1,\n",
    "                    max_completion_tokens=15000\n",
    "                )\n",
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a83960",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.prompt_template = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"\"\"Reasoning:low. \n",
    "                            Your role includes handling text splitting tasks for the RAG pipeline. \n",
    "                            Perfect chunking isnâ€™t about blindly cutting at every paragraph break â€” itâ€™s about finding \n",
    "                            the sweet spot between semantic coherence and retrieval efficiency.\"\"\" ),\n",
    "                (\"user\", self._get_llm_text_splitter_prompt() + \n",
    "                        \"\"\"\\n------------BEGIN-----------\\n\n",
    "                        {text_to_split}\\n\n",
    "                        -----------END----------------\"\"\")\n",
    "            ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_python_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
