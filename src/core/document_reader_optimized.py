# src/core/document_reader_optimized.py
# Module t·ªëi ∆∞u cho vi·ªác ƒë·ªçc v√† ph√¢n t√≠ch c·∫•u tr√∫c t√†i li·ªáu

import logging
import re
from typing import List, Dict, Any, Optional, Set
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ChapterCandidate:
    """C·∫•u tr√∫c d·ªØ li·ªáu cho ·ª©ng vi√™n chapter."""
    number: Optional[int]
    title: str
    line_number: int
    level: int
    quality_score: float
    pattern_type: str
    context_score: float
    importance: str

class OptimizedChapterDetector:
    """
    Chapter Detector ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ t·∫°o c·∫•u tr√∫c ph√¢n t·∫ßng ch√≠nh x√°c.
    S·ª≠ d·ª•ng AI-driven approach ƒë·ªÉ ph√¢n t√≠ch c·∫•u tr√∫c t√†i li·ªáu.
    """
    
    def __init__(self):
        self.profile = {
            'patterns': [
                {
                    'pattern': r'^(Ch∆∞∆°ng|Chapter|CH∆Ø∆†NG)\s+([IVX]+|\d+)[:\.\s]+(.+)$',
                    'type': 'main_chapter',
                    'level': 1,
                    'weight': 10
                },
                {
                    'pattern': r'^(B√†i|Lesson|B√ÄI)\s+(\d+)[:\.\s]+(.+)$',
                    'type': 'main_chapter', 
                    'level': 1,
                    'weight': 9
                },
                {
                    'pattern': r'^(\d+)\.\s+(.+)$',
                    'type': 'numbered_section',
                    'level': 1,
                    'weight': 8
                },
                {
                    'pattern': r'^(\d+)\.(\d+)\.\s+(.+)$',
                    'type': 'sub_section',
                    'level': 2, 
                    'weight': 6
                },
                {
                    'pattern': r'^(\d+)\.(\d+)\.(\d+)\.\s+(.+)$',
                    'type': 'sub_sub_section',
                    'level': 3,
                    'weight': 4
                },
                {
                    'pattern': r'^([A-Z])\.\s+(.+)$',
                    'type': 'alphabetic_section',
                    'level': 2,
                    'weight': 5
                },
                {
                    'pattern': r'^(I+|V+|X+|L+|C+|D+|M+)\.\s+(.+)$',
                    'type': 'roman_section',
                    'level': 1,
                    'weight': 7
                }
            ],
            'important_keywords': [
                'gi·ªõi thi·ªáu', 't·ªïng quan', 'kh√°i ni·ªám', 'c∆° b·∫£n', 'n√¢ng cao',
                '·ª©ng d·ª•ng', 'th·ª±c h√†nh', 'b√†i t·∫≠p', 'v√≠ d·ª•', 'k·∫øt lu·∫≠n',
                't√≥m t·∫Øt', 'ƒë√°nh gi√°', 'ki·ªÉm tra', 'ph∆∞∆°ng ph√°p', 'nguy√™n l√Ω'
            ],
            'exclude_keywords': [
                'trang', 'page', 't√°c gi·∫£', 'author', 'ngu·ªìn', 'source',
                'tham kh·∫£o', 'reference', 'm·ª•c l·ª•c', 'index', 'danh s√°ch'
            ],
            'quality_thresholds': {
                'minimum': 5.0,
                'good': 7.0, 
                'excellent': 9.0
            }
        }
        logger.info("‚úÖ OptimizedChapterDetector ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.")

    def detect_hierarchical_structure(self, text: str) -> List[Dict[str, Any]]:
        """
        Ph√°t hi·ªán c·∫•u tr√∫c ph√¢n t·∫ßng th√¥ng minh c·ªßa t√†i li·ªáu.
        
        Args:
            text (str): N·ªôi dung t√†i li·ªáu ƒë·∫ßy ƒë·ªß
            
        Returns:
            List[Dict]: C·∫•u tr√∫c ph√¢n t·∫ßng ƒë∆∞·ª£c t·ªëi ∆∞u
        """
        logger.info("üîç B·∫Øt ƒë·∫ßu ph√¢n t√≠ch c·∫•u tr√∫c ph√¢n t·∫ßng th√¥ng minh...")
        
        # B∆∞·ªõc 1: Ti·ªÅn x·ª≠ l√Ω v√† chu·∫©n h√≥a vƒÉn b·∫£n
        processed_lines = self._preprocess_text(text)
        
        # B∆∞·ªõc 2: T√¨m t·∫•t c·∫£ ·ª©ng vi√™n chapters
        candidates = self._extract_chapter_candidates(processed_lines)
        
        # B∆∞·ªõc 3: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng v√† ng·ªØ c·∫£nh
        scored_candidates = self._score_candidates(candidates, processed_lines)
        
        # B∆∞·ªõc 4: X√¢y d·ª±ng c·∫•u tr√∫c ph√¢n t·∫ßng
        hierarchical_structure = self._build_hierarchy(scored_candidates)
        
        # B∆∞·ªõc 5: T·ªëi ∆∞u v√† l√†m s·∫°ch k·∫øt qu·∫£
        final_structure = self._optimize_final_structure(hierarchical_structure)
        
        logger.info(f"‚úÖ Ho√†n th√†nh ph√¢n t√≠ch: {len(final_structure)} m·ª•c v·ªõi c·∫•u tr√∫c ph√¢n t·∫ßng.")
        return final_structure

    def _preprocess_text(self, text: str) -> List[str]:
        """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n ƒë·ªÉ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ph√¢n t√≠ch."""
        lines = text.split('\n')
        processed = []
        
        for i, line in enumerate(lines):
            # Chu·∫©n h√≥a spacing v√† encoding
            cleaned = re.sub(r'\s+', ' ', line.strip())
            
            # B·ªè qua d√≤ng tr·ªëng, qu√° ng·∫Øn, ho·∫∑c qu√° d√†i
            if not cleaned or len(cleaned) < 3 or len(cleaned) > 300:
                continue
                
            # B·ªè qua d√≤ng ch·ªâ ch·ª©a s·ªë trang
            if re.match(r'^\d+$', cleaned):
                continue
                
            # B·ªè qua d√≤ng ch·ª©a t·ª´ kh√≥a lo·∫°i tr·ª´
            if any(kw in cleaned.lower() for kw in self.profile['exclude_keywords']):
                continue
                
            processed.append(cleaned)
            
        logger.info(f"ƒê√£ x·ª≠ l√Ω {len(processed)} d√≤ng h·ª£p l·ªá t·ª´ {len(lines)} d√≤ng g·ªëc.")
        return processed

    def _extract_chapter_candidates(self, lines: List[str]) -> List[ChapterCandidate]:
        """Tr√≠ch xu·∫•t t·∫•t c·∫£ ·ª©ng vi√™n chapters v·ªõi th√¥ng tin chi ti·∫øt."""
        candidates = []
        
        for line_idx, line in enumerate(lines[:10000]):  # TƒÉng ph·∫°m vi qu√©t
            for pattern_info in self.profile['patterns']:
                match = re.match(pattern_info['pattern'], line, re.IGNORECASE)
                if match:
                    # Tr√≠ch xu·∫•t th√¥ng tin t·ª´ pattern
                    groups = match.groups()
                    
                    if pattern_info['type'] in ['sub_section', 'sub_sub_section']:
                        # Patterns c√≥ nhi·ªÅu nh√≥m s·ªë
                        number_str = groups[0]  # L·∫•y s·ªë ƒë·∫ßu ti√™n
                        title = groups[-1]      # L·∫•y title cu·ªëi c√πng
                    else:
                        # Patterns ƒë∆°n gi·∫£n
                        number_str = groups[0] if len(groups) > 1 else None
                        title = groups[-1]
                    
                    # T·∫°o candidate
                    candidate = ChapterCandidate(
                        number=self._extract_number(number_str),
                        title=title.strip(),
                        line_number=line_idx,
                        level=pattern_info['level'],
                        quality_score=0.0,  # S·∫Ω t√≠nh sau
                        pattern_type=pattern_info['type'],
                        context_score=0.0,  # S·∫Ω t√≠nh sau
                        importance='medium'
                    )
                    
                    candidates.append(candidate)
                    break  # T√¨m th·∫•y pattern ph√π h·ª£p, chuy·ªÉn d√≤ng ti·∫øp theo
        
        logger.info(f"T√¨m ƒë∆∞·ª£c {len(candidates)} ·ª©ng vi√™n chapters.")
        return candidates

    def _extract_number(self, number_str: Optional[str]) -> Optional[int]:
        """Tr√≠ch xu·∫•t s·ªë t·ª´ chu·ªói (h·ªó tr·ª£ s·ªë La M√£ v√† Arabic)."""
        if not number_str:
            return None
            
        # S·ªë Arabic
        arabic_match = re.search(r'\d+', number_str)
        if arabic_match:
            return int(arabic_match.group())
            
        # S·ªë La M√£ ƒë∆°n gi·∫£n
        roman_map = {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5, 
                    'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10}
        if number_str.upper() in roman_map:
            return roman_map[number_str.upper()]
            
        return None

    def _score_candidates(self, candidates: List[ChapterCandidate], 
                         lines: List[str]) -> List[ChapterCandidate]:
        """ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng t·ª´ng candidate v·ªõi thu·∫≠t to√°n n√¢ng cao."""
        for candidate in candidates:
            # ƒêi·ªÉm c∆° b·∫£n t·ª´ pattern type
            base_score = self._get_pattern_base_score(candidate.pattern_type)
            
            # ƒêi·ªÉm ch·∫•t l∆∞·ª£ng title
            title_score = self._evaluate_title_quality(candidate.title)
            
            # ƒêi·ªÉm ng·ªØ c·∫£nh xung quanh
            context_score = self._evaluate_context(candidate, lines)
            
            # ƒêi·ªÉm v·ªã tr√≠ trong t√†i li·ªáu
            position_score = self._evaluate_position(candidate, len(lines))
            
            # T√≠nh t·ªïng ƒëi·ªÉm c√≥ tr·ªçng s·ªë
            candidate.quality_score = (
                base_score * 0.3 +
                title_score * 0.4 + 
                context_score * 0.2 +
                position_score * 0.1
            )
            
            candidate.context_score = context_score
            
            # ƒê√°nh gi√° m·ª©c ƒë·ªô quan tr·ªçng
            if candidate.quality_score >= self.profile['quality_thresholds']['excellent']:
                candidate.importance = 'high'
            elif candidate.quality_score >= self.profile['quality_thresholds']['good']:
                candidate.importance = 'medium'
            else:
                candidate.importance = 'low'
        
        return candidates

    def _get_pattern_base_score(self, pattern_type: str) -> float:
        """ƒêi·ªÉm c∆° b·∫£n cho t·ª´ng lo·∫°i pattern."""
        scores = {
            'main_chapter': 10.0,
            'numbered_section': 8.0,
            'sub_section': 6.0,
            'sub_sub_section': 4.0,
            'alphabetic_section': 5.0,
            'roman_section': 7.0
        }
        return scores.get(pattern_type, 3.0)

    def _evaluate_title_quality(self, title: str) -> float:
        """ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng ti√™u ƒë·ªÅ."""
        score = 0.0
        
        # ƒê·ªô d√†i ph√π h·ª£p
        if 10 <= len(title) <= 100:
            score += 4.0
        elif 5 <= len(title) <= 150:
            score += 2.0
        else:
            score += 0.5
            
        # Ch·ª©a t·ª´ kh√≥a quan tr·ªçng
        keyword_bonus = sum(2.0 for kw in self.profile['important_keywords'] 
                           if kw in title.lower())
        score += min(keyword_bonus, 6.0)  # T·ªëi ƒëa 6 ƒëi·ªÉm t·ª´ keywords
        
        # C·∫•u tr√∫c ng·ªØ ph√°p t·ªët (c√≥ ƒë·ªông t·ª´, danh t·ª´)
        if re.search(r'[a-zA-Z√Ä-·ªπ]+', title):  # Ch·ª©a ch·ªØ c√°i
            score += 2.0
            
        # Kh√¥ng ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát l·∫°
        if not re.search(r'[^\w\s\-\.\(\)√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒëƒê]', title):
            score += 1.0
            
        return min(score, 10.0)  # T·ªëi ƒëa 10 ƒëi·ªÉm

    def _evaluate_context(self, candidate: ChapterCandidate, lines: List[str]) -> float:
        """ƒê√°nh gi√° ng·ªØ c·∫£nh xung quanh candidate."""
        score = 0.0
        line_idx = candidate.line_number
        
        # L·∫•y ng·ªØ c·∫£nh xung quanh (5 d√≤ng tr∆∞·ªõc v√† sau)
        start_idx = max(0, line_idx - 5)
        end_idx = min(len(lines), line_idx + 5)
        context_lines = lines[start_idx:end_idx]
        context_text = ' '.join(context_lines).lower()
        
        # Bonus n·∫øu c√≥ keywords li√™n quan trong ng·ªØ c·∫£nh
        context_keywords = [
            'm·ª•c ti√™u', 'n·ªôi dung', 'ki·∫øn th·ª©c', 'k·ªπ nƒÉng', 'h·ªçc', 'hi·ªÉu',
            'ph∆∞∆°ng ph√°p', 'c√°ch th·ª©c', 'quy tr√¨nh', 'b∆∞·ªõc', 'giai ƒëo·∫°n'
        ]
        
        keyword_count = sum(1 for kw in context_keywords if kw in context_text)
        score += keyword_count * 0.5
        
        # Bonus n·∫øu d√≤ng tr∆∞·ªõc/sau c√≥ format t∆∞∆°ng t·ª± (c·∫•u tr√∫c nh·∫•t qu√°n)
        if line_idx > 0 and line_idx < len(lines) - 1:
            prev_line = lines[line_idx - 1].strip()
            next_line = lines[line_idx + 1].strip()
            
            # Ki·ªÉm tra t√≠nh nh·∫•t qu√°n format
            if any(re.match(pattern['pattern'], prev_line) or re.match(pattern['pattern'], next_line) 
                  for pattern in self.profile['patterns']):
                score += 2.0
        
        # Penalty n·∫øu qu√° g·∫ßn v·ªõi candidate kh√°c
        nearby_candidates_count = sum(1 for other_line in range(max(0, line_idx-3), min(len(lines), line_idx+3))
                                    if other_line != line_idx and 
                                    any(re.match(p['pattern'], lines[other_line]) for p in self.profile['patterns']))
        if nearby_candidates_count > 2:
            score -= 1.0
            
        return max(0.0, min(score, 10.0))

    def _evaluate_position(self, candidate: ChapterCandidate, total_lines: int) -> float:
        """ƒê√°nh gi√° v·ªã tr√≠ c·ªßa candidate trong t√†i li·ªáu."""
        position_ratio = candidate.line_number / total_lines
        
        # Chapters th∆∞·ªùng xu·∫•t hi·ªán ƒë·∫ßu document ho·∫∑c ph√¢n b·ªë ƒë·ªÅu
        if position_ratio < 0.1:  # 10% ƒë·∫ßu
            return 8.0
        elif position_ratio > 0.9:  # 10% cu·ªëi
            return 3.0
        else:
            return 6.0

    def _build_hierarchy(self, candidates: List[ChapterCandidate]) -> List[Dict[str, Any]]:
        """X√¢y d·ª±ng c·∫•u tr√∫c ph√¢n t·∫ßng t·ª´ candidates."""
        # L·ªçc candidates ch·∫•t l∆∞·ª£ng cao
        quality_candidates = [c for c in candidates 
                            if c.quality_score >= self.profile['quality_thresholds']['minimum']]
        
        # S·∫Øp x·∫øp theo ch·∫•t l∆∞·ª£ng v√† v·ªã tr√≠
        quality_candidates.sort(key=lambda x: (-x.quality_score, x.line_number))
        
        # Ph√¢n lo·∫°i theo level
        level_groups = {1: [], 2: [], 3: []}
        for candidate in quality_candidates:
            if candidate.level in level_groups:
                level_groups[candidate.level].append(candidate)
        
        # X√¢y d·ª±ng c·∫•u tr√∫c ph√¢n t·∫ßng
        hierarchy = []
        
        # Level 1: Main chapters (t·ªëi ƒëa 12)
        main_chapters = level_groups[1][:12]
        
        for i, main_chapter in enumerate(main_chapters):
            main_dict = {
                'number': main_chapter.number or (i + 1),
                'title': main_chapter.title,
                'line_number': main_chapter.line_number,
                'level': 1,
                'display_number': str(i + 1),
                'quality_score': main_chapter.quality_score,
                'children': []
            }
            
            # T√¨m sub-chapters cho main chapter n√†y
            main_line = main_chapter.line_number
            next_main_line = main_chapters[i+1].line_number if i+1 < len(main_chapters) else float('inf')
            
            # Level 2: Sub-chapters
            relevant_subs = [c for c in level_groups[2] 
                           if main_line < c.line_number < next_main_line][:5]  # T·ªëi ƒëa 5 sub
            
            for j, sub_chapter in enumerate(relevant_subs):
                sub_dict = {
                    'number': sub_chapter.number or (j + 1),
                    'title': sub_chapter.title,
                    'line_number': sub_chapter.line_number,
                    'level': 2,
                    'display_number': f"{i + 1}.{j + 1}",
                    'parent_number': str(i + 1),
                    'quality_score': sub_chapter.quality_score,
                    'children': []
                }
                
                # Level 3: Sub-sub-chapters
                sub_line = sub_chapter.line_number
                next_sub_line = relevant_subs[j+1].line_number if j+1 < len(relevant_subs) else next_main_line
                
                relevant_subsubs = [c for c in level_groups[3] 
                                  if sub_line < c.line_number < next_sub_line][:3]  # T·ªëi ƒëa 3 sub-sub
                
                for k, subsub_chapter in enumerate(relevant_subsubs):
                    subsub_dict = {
                        'number': subsub_chapter.number or (k + 1),
                        'title': subsub_chapter.title,
                        'line_number': subsub_chapter.line_number,
                        'level': 3,
                        'display_number': f"{i + 1}.{j + 1}.{k + 1}",
                        'parent_number': f"{i + 1}.{j + 1}",
                        'quality_score': subsub_chapter.quality_score
                    }
                    sub_dict['children'].append(subsub_dict)
                
                main_dict['children'].append(sub_dict)
            
            hierarchy.append(main_dict)
        
        return hierarchy

    def _optimize_final_structure(self, hierarchy: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """T·ªëi ∆∞u c·∫•u tr√∫c cu·ªëi c√πng ƒë·ªÉ ph√π h·ª£p v·ªõi m·ª•c l·ª•c."""
        optimized = []
        
        for main_chapter in hierarchy:
            # L√†m s·∫°ch main chapter
            clean_main = {
                'number': main_chapter['display_number'],
                'title': main_chapter['title'],
                'line_number': main_chapter['line_number'],
                'level': 1
            }
            optimized.append(clean_main)
            
            # Th√™m sub-chapters
            for sub_chapter in main_chapter.get('children', []):
                clean_sub = {
                    'number': sub_chapter['display_number'], 
                    'title': sub_chapter['title'],
                    'line_number': sub_chapter['line_number'],
                    'level': 2
                }
                optimized.append(clean_sub)
                
                # Th√™m sub-sub-chapters
                for subsub_chapter in sub_chapter.get('children', []):
                    clean_subsub = {
                        'number': subsub_chapter['display_number'],
                        'title': subsub_chapter['title'], 
                        'line_number': subsub_chapter['line_number'],
                        'level': 3
                    }
                    optimized.append(clean_subsub)
        
        # S·∫Øp x·∫øp l·∫°i theo line_number ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª±
        optimized.sort(key=lambda x: x['line_number'])
        
        logger.info(f"T·ªëi ∆∞u ho√†n th√†nh: {len(optimized)} m·ª•c trong c·∫•u tr√∫c ph√¢n t·∫ßng.")
        return optimized

    # Compatibility method ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi DocumentReader
    def detect_chapters(self, text: str) -> List[Dict[str, Any]]:
        """
        Method t∆∞∆°ng th√≠ch v·ªõi interface c≈© ƒë·ªÉ kh√¥ng ph√° v·ª° existing code.
        """
        return self.detect_hierarchical_structure(text)

# H√†m ti·ªán √≠ch ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©
def create_optimized_detector() -> OptimizedChapterDetector:
    """Factory function ƒë·ªÉ t·∫°o OptimizedChapterDetector."""
    return OptimizedChapterDetector()