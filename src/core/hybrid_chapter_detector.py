# src/core/hybrid_chapter_detector.py
# Hybrid Chapter Detector vá»›i OCR, Computer Vision vÃ  LLM

import logging
import re
import json
from typing import List, Dict, Any, Optional, Union, Tuple
from dataclasses import dataclass
from pathlib import Path
import cv2
import numpy as np

# OCR Libraries
try:
    import pytesseract
    import easyocr
    from PIL import Image
    HAS_OCR = True
except ImportError:
    HAS_OCR = False
    logging.warning("OCR libraries not installed. Install with: pip install pytesseract easyocr pillow opencv-python")

# PDF handling
try:
    import fitz  # PyMuPDF
    import pdf2image
    HAS_PDF = True
except ImportError:
    HAS_PDF = False
    logging.warning("PDF libraries not installed. Install with: pip install PyMuPDF pdf2image")

logger = logging.getLogger(__name__)

@dataclass
class TOCEntry:
    """Cáº¥u trÃºc dá»¯ liá»‡u cho má»¥c lá»¥c entry."""
    title: str
    page: Optional[int]
    level: int
    confidence: float
    source: str  # 'text', 'ocr', 'cv', 'llm'
    bbox: Optional[Tuple[int, int, int, int]] = None  # Bounding box tá»« CV

class HybridChapterDetector:
    """
    Chapter Detector hybrid káº¿t há»£p nhiá»u phÆ°Æ¡ng phÃ¡p:
    1. Traditional Pattern Matching (cho text cÃ³ cáº¥u trÃºc)
    2. OCR (cho PDF scan vÃ  hÃ¬nh áº£nh)
    3. Computer Vision (Ä‘á»ƒ detect visual structure)
    4. LLM (Ä‘á»ƒ intelligent parsing vÃ  validation)
    """
    
    def __init__(self, llm_provider=None):
        self.llm_provider = llm_provider
        self.ocr_readers = self._initialize_ocr()
        self.pattern_detector = self._initialize_patterns()
        logger.info("âœ… HybridChapterDetector Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o.")

    def _initialize_ocr(self):
        """Khá»Ÿi táº¡o cÃ¡c OCR engines."""
        readers = {}
        if HAS_OCR:
            try:
                readers['easyocr'] = easyocr.Reader(['en', 'vi'])
                readers['tesseract'] = True
                logger.info("âœ… OCR engines Ä‘Ã£ sáºµn sÃ ng (EasyOCR + Tesseract)")
            except Exception as e:
                logger.warning(f"KhÃ´ng thá»ƒ khá»Ÿi táº¡o OCR: {e}")
        return readers

    def _initialize_patterns(self):
        """Khá»Ÿi táº¡o patterns cho traditional detection."""
        return {
            'main_chapter': [
                r'^(Chapter|ChÆ°Æ¡ng|CHAPTER|CHÆ¯Æ NG)\s+([IVX\d]+)[:\.\s]+(.+?)(?:\s*\.+\s*(\d+))?$',
                r'^([IVX\d]+)\.\s+(.+?)(?:\s*\.+\s*(\d+))?$',
                r'^(\d+)\s+(.+?)(?:\s*\.+\s*(\d+))?$'
            ],
            'sub_section': [
                r'^(\d+\.\d+)\s+(.+?)(?:\s*\.+\s*(\d+))?$',
                r'^([A-Z])\.\s+(.+?)(?:\s*\.+\s*(\d+))?$'
            ],
            'sub_sub_section': [
                r'^(\d+\.\d+\.\d+)\s+(.+?)(?:\s*\.+\s*(\d+))?$'
            ]
        }

    def detect_table_of_contents(
        self, 
        source: Union[str, bytes, Path], 
        source_type: str = 'auto'
    ) -> List[TOCEntry]:
        """
        PhÃ¡t hiá»‡n table of contents tá»« nhiá»u nguá»“n khÃ¡c nhau.
        
        Args:
            source: Text, file path, hoáº·c binary data
            source_type: 'text', 'image', 'pdf', 'auto'
            
        Returns:
            List[TOCEntry]: Danh sÃ¡ch entries Ä‘Æ°á»£c detect
        """
        logger.info(f"ğŸ” Báº¯t Ä‘áº§u detect TOC vá»›i source_type: {source_type}")
        
        # Auto-detect source type
        if source_type == 'auto':
            source_type = self._detect_source_type(source)
        
        # Dispatch theo source type
        if source_type == 'text':
            return self._detect_from_text(source)
        elif source_type == 'image':
            return self._detect_from_image(source)
        elif source_type == 'pdf':
            return self._detect_from_pdf(source)
        else:
            logger.error(f"Unsupported source_type: {source_type}")
            return []

    def _detect_source_type(self, source) -> str:
        """Auto-detect loáº¡i source."""
        if isinstance(source, str):
            if source.lower().endswith(('.pdf',)):
                return 'pdf'
            elif source.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
                return 'image'
            else:
                return 'text'
        elif isinstance(source, (bytes, Path)):
            return 'pdf'  # Assume binary data is PDF
        else:
            return 'text'

    def _detect_from_text(self, text: str) -> List[TOCEntry]:
        """Detect TOC tá»« plain text sá»­ dá»¥ng pattern matching + LLM."""
        logger.info("ğŸ“ Detecting tá»« text vá»›i pattern matching + LLM")
        
        entries = []
        lines = text.split('\n')
        
        # Phase 1: Pattern-based detection
        pattern_entries = self._pattern_based_detection(lines)
        entries.extend(pattern_entries)
        
        # Phase 2: LLM-based enhancement náº¿u cÃ³ LLM provider
        if self.llm_provider and len(entries) < 5:
            llm_entries = self._llm_based_detection(text)
            entries.extend(llm_entries)
        
        # Phase 3: Merge vÃ  deduplicate
        return self._merge_and_deduplicate(entries)

    def _detect_from_image(self, image_source: Union[str, Path, np.ndarray]) -> List[TOCEntry]:
        """Detect TOC tá»« hÃ¬nh áº£nh sá»­ dá»¥ng OCR + Computer Vision."""
        if not HAS_OCR:
            logger.error("OCR libraries not available for image processing")
            return []
            
        logger.info("ğŸ–¼ï¸ Detecting tá»« image vá»›i OCR + Computer Vision")
        
        # Load image
        if isinstance(image_source, (str, Path)):
            image = cv2.imread(str(image_source))
        else:
            image = image_source
            
        if image is None:
            logger.error("KhÃ´ng thá»ƒ load image")
            return []
        
        entries = []
        
        # Phase 1: OCR-based detection
        ocr_entries = self._ocr_based_detection(image)
        entries.extend(ocr_entries)
        
        # Phase 2: Computer Vision-based structure detection
        cv_entries = self._computer_vision_detection(image)
        entries.extend(cv_entries)
        
        # Phase 3: LLM validation
        if self.llm_provider:
            validated_entries = self._llm_validate_entries(entries, image)
            return validated_entries
        
        return self._merge_and_deduplicate(entries)

    def _detect_from_pdf(self, pdf_source: Union[str, Path, bytes]) -> List[TOCEntry]:
        """Detect TOC tá»« PDF sá»­ dá»¥ng táº¥t cáº£ phÆ°Æ¡ng phÃ¡p."""
        if not HAS_PDF:
            logger.error("PDF libraries not available")
            return []
            
        logger.info("ğŸ“„ Detecting tá»« PDF vá»›i multiple approaches")
        
        entries = []
        
        # Phase 1: Extract embedded TOC tá»« PDF metadata
        metadata_entries = self._extract_pdf_toc_metadata(pdf_source)
        entries.extend(metadata_entries)
        
        # Phase 2: OCR trÃªn cÃ¡c trang Ä‘áº§u (thÆ°á»ng chá»©a TOC)
        if len(entries) < 5:  # Náº¿u metadata khÃ´ng Ä‘á»§
            ocr_entries = self._extract_pdf_toc_ocr(pdf_source)
            entries.extend(ocr_entries)
        
        # Phase 3: Full text extraction + pattern matching
        text_entries = self._extract_pdf_toc_text(pdf_source)
        entries.extend(text_entries)
        
        return self._merge_and_deduplicate(entries)

    def _pattern_based_detection(self, lines: List[str]) -> List[TOCEntry]:
        """Traditional pattern matching approach Ä‘Æ°á»£c cáº£i tiáº¿n."""
        entries = []
        
        for line_idx, line in enumerate(lines):
            line_clean = line.strip()
            if not line_clean or len(line_clean) < 3:
                continue
                
            # Thá»­ match vá»›i cÃ¡c patterns
            for level, (level_name, patterns) in enumerate(self.pattern_detector.items(), 1):
                for pattern in patterns:
                    match = re.search(pattern, line_clean, re.IGNORECASE)
                    if match:
                        groups = match.groups()
                        
                        # Extract thÃ´ng tin
                        if len(groups) >= 2:
                            number = groups[0]
                            title = groups[1]
                            page = int(groups[2]) if len(groups) > 2 and groups[2] and groups[2].isdigit() else None
                        else:
                            number = None
                            title = groups[0] if groups else line_clean
                            page = None
                        
                        entry = TOCEntry(
                            title=title.strip(),
                            page=page,
                            level=level,
                            confidence=0.8,
                            source='text'
                        )
                        entries.append(entry)
                        break
                else:
                    continue
                break
        
        return entries

    def _llm_based_detection(self, text: str) -> List[TOCEntry]:
        """Sá»­ dá»¥ng LLM Ä‘á»ƒ detect vÃ  parse table of contents."""
        if not self.llm_provider:
            return []
            
        logger.info("ğŸ¤– Sá»­ dá»¥ng LLM Ä‘á»ƒ detect table of contents")
        
        system_prompt = """
        Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch cáº¥u trÃºc tÃ i liá»‡u. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tÃ¬m vÃ  trÃ­ch xuáº¥t 
        table of contents (má»¥c lá»¥c) tá»« vÄƒn báº£n, ká»ƒ cáº£ khi nÃ³ khÃ´ng cÃ³ format chuáº©n.

        QUY Táº®C:
        - LUÃ”N tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
        - Chá»‰ tráº£ vá» JSON array, khÃ´ng giáº£i thÃ­ch thÃªm
        """
        
        user_prompt = f"""
        PhÃ¢n tÃ­ch vÄƒn báº£n sau vÃ  tÃ¬m table of contents. Tráº£ vá» JSON array vá»›i format:
        [
            {{"title": "TiÃªu Ä‘á» chÆ°Æ¡ng/má»¥c", "page": sá»‘_trang_hoáº·c_null, "level": cáº¥p_Ä‘á»™_1_2_3}}
        ]

        VÄƒn báº£n:
        {text[:8000]}...
        """
        
        try:
            response = self.llm_provider.generate(
                system_prompt=system_prompt,
                user_prompt=user_prompt
            )
            
            # Parse JSON response
            import json
            json_match = re.search(r'\[.*?\]', response, re.DOTALL)
            if json_match:
                entries_data = json.loads(json_match.group())
                return [
                    TOCEntry(
                        title=entry['title'],
                        page=entry.get('page'),
                        level=entry.get('level', 1),
                        confidence=0.7,
                        source='llm'
                    )
                    for entry in entries_data
                ]
        except Exception as e:
            logger.error(f"LLM detection failed: {e}")
        
        return []

    def _ocr_based_detection(self, image: np.ndarray) -> List[TOCEntry]:
        """OCR-based detection vá»›i EasyOCR vÃ  Tesseract."""
        entries = []
        
        if 'easyocr' in self.ocr_readers:
            try:
                # EasyOCR detection
                results = self.ocr_readers['easyocr'].readtext(image)
                
                for bbox, text, confidence in results:
                    if confidence > 0.5 and len(text.strip()) > 3:
                        # PhÃ¢n tÃ­ch text Ä‘á»ƒ xÃ¡c Ä‘á»‹nh level vÃ  page
                        level = self._analyze_text_level(text)
                        page = self._extract_page_number(text)
                        
                        entry = TOCEntry(
                            title=text.strip(),
                            page=page,
                            level=level,
                            confidence=confidence,
                            source='ocr',
                            bbox=tuple(map(int, bbox[0] + bbox[2]))  # Convert to (x1,y1,x2,y2)
                        )
                        entries.append(entry)
            except Exception as e:
                logger.error(f"EasyOCR failed: {e}")
        
        return entries

    def _computer_vision_detection(self, image: np.ndarray) -> List[TOCEntry]:
        """Computer Vision Ä‘á»ƒ detect visual structure cá»§a TOC."""
        entries = []
        
        try:
            # Convert to grayscale
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Detect lines (cho dotted lines trong TOC)
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)
            
            # Detect text regions
            contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # Analyze layout Ä‘á»ƒ determine TOC structure
            for contour in contours:
                x, y, w, h = cv2.boundingRect(contour)
                if w > 100 and h > 15:  # Reasonable text size
                    # Estimate level based on x position (indentation)
                    level = max(1, (x // 30) + 1)
                    
                    # Extract text trong region nÃ y (cáº§n OCR)
                    roi = image[y:y+h, x:x+w]
                    # ... OCR processing cho roi
                    
            logger.info(f"CV detected {len(entries)} potential TOC entries")
            
        except Exception as e:
            logger.error(f"Computer vision detection failed: {e}")
        
        return entries

    def _extract_pdf_toc_metadata(self, pdf_source) -> List[TOCEntry]:
        """Extract TOC tá»« PDF metadata/bookmarks."""
        if not HAS_PDF:
            return []
            
        entries = []
        try:
            doc = fitz.open(pdf_source)
            toc = doc.get_toc()
            
            for level, title, page in toc:
                entry = TOCEntry(
                    title=title,
                    page=page,
                    level=level,
                    confidence=0.95,
                    source='pdf_metadata'
                )
                entries.append(entry)
                
            doc.close()
            logger.info(f"Extracted {len(entries)} tá»« PDF metadata")
            
        except Exception as e:
            logger.error(f"PDF metadata extraction failed: {e}")
            
        return entries

    def _extract_pdf_toc_ocr(self, pdf_source) -> List[TOCEntry]:
        """OCR trÃªn cÃ¡c trang Ä‘áº§u cá»§a PDF Ä‘á»ƒ tÃ¬m TOC."""
        if not HAS_PDF or not HAS_OCR:
            return []
            
        entries = []
        try:
            # Convert cÃ¡c trang Ä‘áº§u thÃ nh images
            images = pdf2image.convert_from_path(pdf_source, first_page=1, last_page=5)
            
            for page_num, image in enumerate(images, 1):
                # Convert PIL to OpenCV
                cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
                
                # OCR detection
                page_entries = self._ocr_based_detection(cv_image)
                
                # Filter Ä‘á»ƒ chá»‰ giá»¯ entries cÃ³ váº» nhÆ° TOC
                toc_entries = [e for e in page_entries if self._looks_like_toc_entry(e.title)]
                entries.extend(toc_entries)
                
            logger.info(f"OCR trÃªn PDF tÃ¬m Ä‘Æ°á»£c {len(entries)} entries")
            
        except Exception as e:
            logger.error(f"PDF OCR failed: {e}")
            
        return entries

    def _extract_pdf_toc_text(self, pdf_source) -> List[TOCEntry]:
        """Extract text tá»« PDF vÃ  pattern matching."""
        if not HAS_PDF:
            return []
            
        try:
            doc = fitz.open(pdf_source)
            full_text = ""
            
            # Extract text tá»« 10 trang Ä‘áº§u
            for page_num in range(min(10, doc.page_count)):
                page = doc[page_num]
                full_text += page.get_text()
                
            doc.close()
            
            # Pattern matching trÃªn full text
            return self._detect_from_text(full_text)
            
        except Exception as e:
            logger.error(f"PDF text extraction failed: {e}")
            return []

    def _analyze_text_level(self, text: str) -> int:
        """PhÃ¢n tÃ­ch text Ä‘á»ƒ xÃ¡c Ä‘á»‹nh level (1, 2, 3...)."""
        # Check for numbering patterns
        if re.match(r'^\d+\.\d+\.\d+', text):
            return 3
        elif re.match(r'^\d+\.\d+', text):
            return 2
        elif re.match(r'^\d+\.', text) or re.match(r'^(Chapter|ChÆ°Æ¡ng)', text, re.I):
            return 1
        else:
            return 2  # Default

    def _extract_page_number(self, text: str) -> Optional[int]:
        """Extract page number tá»« text."""
        # Look for patterns nhÆ° "... 25" hoáº·c "... page 25"
        matches = re.findall(r'\.+\s*(\d+)$', text)
        if matches:
            return int(matches[-1])
        
        matches = re.findall(r'\b(\d+)\s*$', text)
        if matches:
            return int(matches[-1])
            
        return None

    def _looks_like_toc_entry(self, text: str) -> bool:
        """Kiá»ƒm tra xem text cÃ³ giá»‘ng TOC entry khÃ´ng."""
        # Heuristics Ä‘á»ƒ identify TOC entries
        if len(text.strip()) < 5:
            return False
            
        # Has page number at end
        if re.search(r'\.+\s*\d+\s*$', text):
            return True
            
        # Has chapter/section indicators
        if re.search(r'^(Chapter|ChÆ°Æ¡ng|Section|Pháº§n|\d+\.)', text, re.I):
            return True
            
        # Reasonable length
        if 10 <= len(text) <= 150:
            return True
            
        return False

    def _merge_and_deduplicate(self, entries: List[TOCEntry]) -> List[TOCEntry]:
        """Merge entries tá»« cÃ¡c sources vÃ  loáº¡i bá» duplicates."""
        if not entries:
            return []
            
        # Sort theo confidence vÃ  source priority
        source_priority = {'pdf_metadata': 4, 'text': 3, 'ocr': 2, 'llm': 1, 'cv': 0}
        entries.sort(key=lambda x: (-x.confidence, -source_priority.get(x.source, 0)))
        
        # Deduplicate based on title similarity
        unique_entries = []
        seen_titles = set()
        
        for entry in entries:
            title_normalized = re.sub(r'\s+', ' ', entry.title.lower().strip())
            
            # Check similarity vá»›i existing titles
            is_duplicate = False
            for seen_title in seen_titles:
                if self._text_similarity(title_normalized, seen_title) > 0.8:
                    is_duplicate = True
                    break
                    
            if not is_duplicate:
                unique_entries.append(entry)
                seen_titles.add(title_normalized)
        
        # Sort theo level vÃ  page
        unique_entries.sort(key=lambda x: (x.level, x.page or 0))
        
        logger.info(f"Merged {len(entries)} entries into {len(unique_entries)} unique entries")
        return unique_entries

    def _text_similarity(self, text1: str, text2: str) -> float:
        """Simple text similarity score."""
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
            
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0

    def _llm_validate_entries(self, entries: List[TOCEntry], image: np.ndarray) -> List[TOCEntry]:
        """Sá»­ dá»¥ng LLM Ä‘á»ƒ validate vÃ  improve entries."""
        if not self.llm_provider or not entries:
            return entries
            
        # Convert entries to text format for LLM
        entries_text = "\n".join([
            f"Level {e.level}: {e.title} (Page {e.page or '?'}) [Confidence: {e.confidence:.2f}]"
            for e in entries
        ])
        
        system_prompt = """
        Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch table of contents. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  validate vÃ  cáº£i thiá»‡n 
        káº¿t quáº£ detect tá»« OCR/CV, loáº¡i bá» noise vÃ  sá»­a lá»—i.

        QUY Táº®C: LUÃ”N tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
        """
        
        user_prompt = f"""
        ÄÃ¢y lÃ  káº¿t quáº£ detect table of contents tá»« hÃ¬nh áº£nh:

        {entries_text}

        HÃ£y validate vÃ  improve káº¿t quáº£ nÃ y:
        1. Loáº¡i bá» entries khÃ´ng pháº£i TOC (noise)
        2. Sá»­a lá»—i OCR trong title
        3. XÃ¡c Ä‘á»‹nh Ä‘Ãºng level hierarchy
        4. Tráº£ vá» JSON array cáº£i thiá»‡n

        Format: [{{"title": "...", "page": ..., "level": ...}}]
        """
        
        try:
            response = self.llm_provider.generate(
                system_prompt=system_prompt,
                user_prompt=user_prompt
            )
            
            # Parse improved entries
            json_match = re.search(r'\[.*?\]', response, re.DOTALL)
            if json_match:
                improved_data = json.loads(json_match.group())
                return [
                    TOCEntry(
                        title=entry['title'],
                        page=entry.get('page'),
                        level=entry.get('level', 1),
                        confidence=0.9,
                        source='llm_validated'
                    )
                    for entry in improved_data
                ]
        except Exception as e:
            logger.error(f"LLM validation failed: {e}")
        
        return entries

    # Method Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i interface cÅ©
    def detect_chapters(self, text: str) -> List[Dict[str, Any]]:
        """Compatibility method cho interface cÅ©."""
        entries = self.detect_table_of_contents(text, 'text')
        
        # Convert TOCEntry to old format
        return [
            {
                'number': i + 1,
                'title': entry.title,
                'line_number': 0,  # KhÃ´ng cÃ³ line number trong new format
                'level': entry.level,
                'page': entry.page
            }
            for i, entry in enumerate(entries)
        ]