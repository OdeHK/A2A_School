# src/agents/context_aware_quiz_agent.py
# Context-aware quiz generation agent - NO EXAMPLE LEAK

import logging
import json
import re
from typing import Dict, Any, List, Optional

from ..core.llm_provider import LLMProvider

logger = logging.getLogger(__name__)

class ContextAwareQuizAgent:
    """
    Quiz generation agent that STRICTLY uses only the provided document content.
    Designed to prevent context leak and generate questions only from actual content.
    """
    
    def __init__(self, llm_provider: LLMProvider):
        self.llm_provider = llm_provider
        self.generated_questions = []
        logger.info("‚úÖ ContextAwareQuizAgent initialized with strict content-only mode")

    def generate_content_based_questions(
        self, 
        document_content: str, 
        section_title: str,
        num_questions: int = 5,
        question_type: str = "multiple_choice",
        difficulty: str = "medium"
    ) -> List[Dict[str, Any]]:
        """
        Generate questions STRICTLY from document content only.
        
        Args:
            document_content (str): The actual document text to create questions from
            section_title (str): Title of the section for context
            num_questions (int): Number of questions to generate
            question_type (str): Type of questions (multiple_choice, true_false, essay)
            difficulty (str): Difficulty level (easy, medium, hard)
            
        Returns:
            List[Dict]: Questions generated from document content only
        """
        logger.info(f"üéØ Generating {num_questions} {question_type} questions from content: {section_title}")
        
        # Analyze content first to ensure we have enough material
        content_analysis = self._analyze_content_for_questions(document_content)
        
        if not content_analysis['suitable_for_questions']:
            logger.warning("‚ö†Ô∏è Document content may not be suitable for question generation")
            return []
        
        if question_type == "multiple_choice":
            return self._generate_multiple_choice_from_content(
                document_content, section_title, num_questions, difficulty
            )
        elif question_type == "true_false":
            return self._generate_true_false_from_content(
                document_content, section_title, num_questions, difficulty
            )
        elif question_type == "essay":
            return self._generate_essay_from_content(
                document_content, section_title, num_questions, difficulty
            )
        else:
            logger.error(f"Unsupported question type: {question_type}")
            return []

    def _analyze_content_for_questions(self, content: str) -> Dict[str, Any]:
        """Analyze if content is suitable for question generation."""
        analysis = {
            'suitable_for_questions': False,
            'content_length': len(content),
            'has_concepts': False,
            'has_facts': False,
            'has_examples': False,
            'key_topics': []
        }
        
        # Check content length
        if len(content) < 200:
            return analysis
        
        # Look for conceptual content
        concept_indicators = [
            'ƒë·ªãnh nghƒ©a', 'kh√°i ni·ªám', 'l√† g√¨', 't·ª©c l√†', 'c√≥ nghƒ©a', 'ƒë∆∞·ª£c hi·ªÉu',
            'definition', 'concept', 'means', 'refers to', 'defined as'
        ]
        analysis['has_concepts'] = any(indicator in content.lower() for indicator in concept_indicators)
        
        # Look for factual content
        fact_indicators = [
            'nƒÉm', 'ng√†y', 'th√°ng', 'ƒë∆∞·ª£c t·∫°o', 'ph√°t minh', 'ph√°t tri·ªÉn',
            's·ªë l∆∞·ª£ng', 'ph·∫ßn trƒÉm', 'bao g·ªìm', 'consists of', 'includes'
        ]
        analysis['has_facts'] = any(indicator in content.lower() for indicator in fact_indicators)
        
        # Look for examples
        example_indicators = [
            'v√≠ d·ª•', 'ch·∫≥ng h·∫°n', 'nh∆∞ l√†', 'for example', 'such as', 'instance'
        ]
        analysis['has_examples'] = any(indicator in content.lower() for indicator in example_indicators)
        
        # Extract key topics (simplified)
        sentences = content.split('.')
        key_topics = []
        for sentence in sentences[:10]:  # Analyze first 10 sentences
            if len(sentence.strip()) > 50:  # Meaningful sentences
                key_topics.append(sentence.strip()[:100])  # First 100 chars
        
        analysis['key_topics'] = key_topics
        analysis['suitable_for_questions'] = (
            analysis['has_concepts'] or 
            analysis['has_facts'] or 
            len(analysis['key_topics']) >= 3
        )
        
        return analysis

    def _generate_multiple_choice_from_content(
        self, 
        content: str, 
        section_title: str, 
        num_questions: int, 
        difficulty: str
    ) -> List[Dict[str, Any]]:
        """Generate multiple choice questions from content only."""
        
        # Extract key information from content
        content_summary = self._extract_key_information(content)
        
        system_prompt = """
        B·∫°n l√† gi√°o vi√™n chuy√™n nghi·ªáp t·∫°o c√¢u h·ªèi ki·ªÉm tra t·ª´ t√†i li·ªáu h·ªçc t·∫≠p.
        
        QUY T·∫ÆC NGHI√äM NG·∫∂T:
        - CH·ªà t·∫°o c√¢u h·ªèi d·ª±a tr√™n n·ªôi dung t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p
        - KH√îNG s·ª≠ d·ª•ng ki·∫øn th·ª©c b√™n ngo√†i t√†i li·ªáu
        - KH√îNG t·∫°o v√≠ d·ª• t·ª´ ki·∫øn th·ª©c ri√™ng c·ªßa b·∫°n
        - LU√îN tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
        - ƒê·∫£m b·∫£o c√¢u h·ªèi c√≥ th·ªÉ tr·∫£ l·ªùi ƒë∆∞·ª£c t·ª´ n·ªôi dung ƒë√£ cho
        """
        
        user_prompt = f"""
        ## NHI·ªÜM V·ª§: T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám t·ª´ n·ªôi dung t√†i li·ªáu

        ### TH√îNG TIN M·∫†CH:
        - Ch·ªß ƒë·ªÅ: {section_title}
        - S·ªë c√¢u h·ªèi: {num_questions}
        - M·ª©c ƒë·ªô: {difficulty}

        ### N·ªòI DUNG T√ÄI LI·ªÜU (CH·ªà S·ª¨ D·ª§NG TH√îNG TIN N√ÄY):
        ```
        {content[:6000]}
        ```

        ### Y√äU C·∫¶U:
        1. CH·ªà t·∫°o c√¢u h·ªèi t·ª´ n·ªôi dung tr√™n
        2. ƒê·∫£m b·∫£o ƒë√°p √°n c√≥ trong n·ªôi dung
        3. T·∫°o c√°c ph∆∞∆°ng √°n nhi·ªÖu h·ª£p l√Ω nh∆∞ng sai theo n·ªôi dung
        4. Gi·∫£i th√≠ch d·ª±a tr√™n ƒëo·∫°n vƒÉn c·ª• th·ªÉ trong t√†i li·ªáu

        ### ƒê·ªäNH D·∫†NG JSON:
        ```json
        [
            {{
                "question_id": 1,
                "question_text": "C√¢u h·ªèi d·ª±a tr√™n n·ªôi dung t√†i li·ªáu?",
                "options": {{
                    "A": "ƒê√°p √°n A t·ª´ t√†i li·ªáu",
                    "B": "ƒê√°p √°n B t·ª´ t√†i li·ªáu", 
                    "C": "ƒê√°p √°n C t·ª´ t√†i li·ªáu",
                    "D": "ƒê√°p √°n D t·ª´ t√†i li·ªáu"
                }},
                "correct_answer": "A",
                "explanation": {{
                    "correct_reason": "ƒê√∫ng v√¨ trong t√†i li·ªáu c√≥ ƒë·ªÅ c·∫≠p: [tr√≠ch d·∫´n c·ª• th·ªÉ]",
                    "content_reference": "ƒêo·∫°n vƒÉn ho·∫∑c c√¢u c·ª• th·ªÉ trong t√†i li·ªáu l√†m cƒÉn c·ª©"
                }},
                "source_content": "Tr√≠ch d·∫´n ƒëo·∫°n vƒÉn t·ª´ t√†i li·ªáu l√†m c∆° s·ªü cho c√¢u h·ªèi"
            }}
        ]
        ```

        ### L∆ØU √ù QUAN TR·ªåNG:
        - M·ªói c√¢u h·ªèi ph·∫£i c√≥ tr∆∞·ªùng "source_content" tr√≠ch d·∫´n t·ª´ t√†i li·ªáu
        - Gi·∫£i th√≠ch ph·∫£i tham chi·∫øu c·ª• th·ªÉ ƒë·∫øn n·ªôi dung
        - KH√îNG ƒë∆∞·ª£c s·ª≠ d·ª•ng th√¥ng tin ngo√†i t√†i li·ªáu

        T·∫°o {num_questions} c√¢u h·ªèi ch·∫•t l∆∞·ª£ng cao:
        """
        
        try:
            response = self.llm_provider.generate(
                system_prompt=system_prompt,
                user_prompt=user_prompt
            )
            
            # Extract and parse JSON
            questions_json = self._extract_json_from_response(response)
            questions = json.loads(questions_json)
            
            # Validate that questions are content-based
            validated_questions = self._validate_content_based_questions(questions, content)
            
            logger.info(f"‚úÖ Generated {len(validated_questions)} content-based questions")
            return validated_questions
            
        except Exception as e:
            logger.error(f"‚ùå Error generating questions: {e}")
            return []

    def _generate_true_false_from_content(
        self, 
        content: str, 
        section_title: str, 
        num_questions: int, 
        difficulty: str
    ) -> List[Dict[str, Any]]:
        """Generate true/false questions from content only."""
        
        system_prompt = """
        B·∫°n l√† gi√°o vi√™n t·∫°o c√¢u h·ªèi ƒë√∫ng/sai t·ª´ t√†i li·ªáu h·ªçc t·∫≠p.
        
        QUY T·∫ÆC:
        - CH·ªà t·∫°o c√¢u h·ªèi t·ª´ n·ªôi dung t√†i li·ªáu
        - C√¢u h·ªèi ph·∫£i r√µ r√†ng l√† ƒë√∫ng ho·∫∑c sai theo t√†i li·ªáu
        - Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
        """
        
        user_prompt = f"""
        ## NHI·ªÜM V·ª§: T·∫°o c√¢u h·ªèi ƒë√∫ng/sai t·ª´ n·ªôi dung

        ### N·ªòI DUNG T√ÄI LI·ªÜU:
        ```
        {content[:5000]}
        ```

        ### Y√äU C·∫¶U:
        - T·∫°o {num_questions} c√¢u h·ªèi ƒë√∫ng/sai
        - D·ª±a tr√™n th√¥ng tin ch√≠nh x√°c trong t√†i li·ªáu
        - Mix c√¢u ƒë√∫ng v√† c√¢u sai

        ### ƒê·ªäNH D·∫†NG JSON:
        ```json
        [
            {{
                "question_id": 1,
                "question_text": "Kh·∫≥ng ƒë·ªãnh v·ªÅ n·ªôi dung trong t√†i li·ªáu",
                "correct_answer": true,
                "explanation": "Gi·∫£i th√≠ch d·ª±a tr√™n n·ªôi dung t√†i li·ªáu",
                "source_content": "Tr√≠ch d·∫´n t·ª´ t√†i li·ªáu"
            }}
        ]
        ```

        T·∫°o c√¢u h·ªèi:
        """
        
        try:
            response = self.llm_provider.generate(system_prompt=system_prompt, user_prompt=user_prompt)
            questions_json = self._extract_json_from_response(response)
            questions = json.loads(questions_json)
            
            # Add question type
            for q in questions:
                q['question_type'] = 'true_false'
                q['topic'] = section_title
            
            return questions
            
        except Exception as e:
            logger.error(f"Error generating true/false questions: {e}")
            return []

    def _generate_essay_from_content(
        self, 
        content: str, 
        section_title: str, 
        num_questions: int, 
        difficulty: str
    ) -> List[Dict[str, Any]]:
        """Generate essay questions from content only."""
        
        system_prompt = """
        B·∫°n l√† gi√°o vi√™n t·∫°o c√¢u h·ªèi t·ª± lu·∫≠n t·ª´ t√†i li·ªáu h·ªçc t·∫≠p.
        
        QUY T·∫ÆC:
        - C√¢u h·ªèi ph·∫£i c√≥ th·ªÉ tr·∫£ l·ªùi ƒë∆∞·ª£c t·ª´ n·ªôi dung t√†i li·ªáu
        - Kh√¥ng y√™u c·∫ßu ki·∫øn th·ª©c b√™n ngo√†i t√†i li·ªáu
        - Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
        """
        
        user_prompt = f"""
        ## NHI·ªÜM V·ª§: T·∫°o c√¢u h·ªèi t·ª± lu·∫≠n t·ª´ n·ªôi dung

        ### N·ªòI DUNG T√ÄI LI·ªÜU:
        ```
        {content[:5000]}
        ```

        ### Y√äU C·∫¶U:
        - T·∫°o {num_questions} c√¢u h·ªèi t·ª± lu·∫≠n
        - H·ªçc sinh c√≥ th·ªÉ tr·∫£ l·ªùi t·ª´ n·ªôi dung ƒë√£ cho
        - Bao g·ªìm h∆∞·ªõng d·∫´n ch·∫•m ƒëi·ªÉm

        ### ƒê·ªäNH D·∫†NG JSON:
        ```json
        [
            {{
                "question_id": 1,
                "question_text": "C√¢u h·ªèi t·ª± lu·∫≠n v·ªÅ n·ªôi dung",
                "expected_length": "150-200 t·ª´",
                "scoring_criteria": {{
                    "key_points": ["ƒêi·ªÉm 1 t·ª´ t√†i li·ªáu", "ƒêi·ªÉm 2 t·ª´ t√†i li·ªáu"],
                    "examples_required": true
                }},
                "sample_answer": "C√¢u tr·∫£ l·ªùi m·∫´u d·ª±a tr√™n t√†i li·ªáu",
                "source_content": "Ph·∫ßn t√†i li·ªáu li√™n quan"
            }}
        ]
        ```

        T·∫°o c√¢u h·ªèi:
        """
        
        try:
            response = self.llm_provider.generate(system_prompt=system_prompt, user_prompt=user_prompt)
            questions_json = self._extract_json_from_response(response)
            questions = json.loads(questions_json)
            
            # Add question type
            for q in questions:
                q['question_type'] = 'essay'
                q['topic'] = section_title
            
            return questions
            
        except Exception as e:
            logger.error(f"Error generating essay questions: {e}")
            return []

    def _extract_key_information(self, content: str) -> Dict[str, List[str]]:
        """Extract key information categories from content."""
        info = {
            'definitions': [],
            'facts': [],
            'processes': [],
            'examples': []
        }
        
        sentences = content.split('.')
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) < 20:
                continue
                
            # Look for definitions
            if any(word in sentence.lower() for word in ['ƒë·ªãnh nghƒ©a', 'l√†', 't·ª©c l√†', 'c√≥ nghƒ©a']):
                info['definitions'].append(sentence)
            
            # Look for facts
            elif any(word in sentence.lower() for word in ['nƒÉm', 'ƒë∆∞·ª£c t·∫°o', 'ph√°t tri·ªÉn', 'bao g·ªìm']):
                info['facts'].append(sentence)
            
            # Look for processes
            elif any(word in sentence.lower() for word in ['b∆∞·ªõc', 'quy tr√¨nh', 'c√°ch', 'ph∆∞∆°ng ph√°p']):
                info['processes'].append(sentence)
            
            # Look for examples
            elif any(word in sentence.lower() for word in ['v√≠ d·ª•', 'ch·∫≥ng h·∫°n', 'nh∆∞']):
                info['examples'].append(sentence)
        
        # Limit each category
        for key in info:
            info[key] = info[key][:5]  # Max 5 items per category
        
        return info

    def _validate_content_based_questions(self, questions: List[Dict], content: str) -> List[Dict]:
        """Validate that questions are truly based on content."""
        validated = []
        
        for question in questions:
            # Check if question has source_content field
            if 'source_content' not in question:
                logger.warning(f"Question {question.get('question_id')} missing source_content")
                continue
            
            # Check if source content exists in the document
            source_content = question['source_content']
            if source_content and any(part.strip() in content for part in source_content.split() if len(part) > 5):
                validated.append(question)
            else:
                logger.warning(f"Question {question.get('question_id')} source not found in content")
        
        return validated

    def _extract_json_from_response(self, response: str) -> str:
        """Extract JSON from LLM response."""
        # Try to find JSON in code blocks
        json_patterns = [
            r'```json\s*(\[.*?\])\s*```',
            r'```\s*(\[.*?\])\s*```', 
            r'(\[.*?\])'
        ]
        
        for pattern in json_patterns:
            match = re.search(pattern, response, re.DOTALL)
            if match:
                return match.group(1)
        
        return response.strip()

    def generate_quiz_from_pdf_structure(
        self, 
        pdf_structure: Dict[str, Any], 
        quiz_requirements: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Generate quiz from PDF structure analysis.
        
        Args:
            pdf_structure: Output from ProfessionalPDFProcessor
            quiz_requirements: Requirements for quiz generation
            
        Returns:
            List of questions based on PDF content
        """
        logger.info("üìù Generating quiz from PDF structure...")
        
        all_questions = []
        content = pdf_structure.get('text_content', '')
        bookmarks = pdf_structure.get('bookmarks', [])
        
        # Generate questions for each major section
        for bookmark in bookmarks[:5]:  # Limit to first 5 major sections
            if bookmark['level'] <= 2:  # Only major sections
                section_content = self._extract_section_content_from_full_text(
                    content, bookmark['title']
                )
                
                if len(section_content) > 200:  # Ensure sufficient content
                    section_questions = self.generate_content_based_questions(
                        document_content=section_content,
                        section_title=bookmark['title'],
                        num_questions=quiz_requirements.get('questions_per_section', 2),
                        question_type=quiz_requirements.get('question_type', 'multiple_choice'),
                        difficulty=quiz_requirements.get('difficulty', 'medium')
                    )
                    all_questions.extend(section_questions)
        
        logger.info(f"‚úÖ Generated {len(all_questions)} questions from PDF structure")
        return all_questions

    def _extract_section_content_from_full_text(self, full_text: str, section_title: str) -> str:
        """Extract content for a specific section from full text."""
        lines = full_text.split('\n')
        section_lines = []
        capturing = False
        
        for line in lines:
            line_clean = line.strip()
            if not line_clean:
                if capturing:
                    section_lines.append('')
                continue
            
            # Check if this line contains the section title
            if section_title.lower() in line_clean.lower():
                capturing = True
                section_lines.append(line_clean)
                continue
            
            if capturing:
                # Check if we hit another major section
                if any(keyword in line_clean.lower() for keyword in ['chapter', 'ch∆∞∆°ng', 'b√†i']):
                    # If this looks like a new section and we have enough content, stop
                    if len('\n'.join(section_lines)) > 500:
                        break
                
                section_lines.append(line_clean)
                
                # Limit section size to avoid token overflow
                if len(section_lines) > 100:
                    break
        
        return '\n'.join(section_lines)


# Compatibility function for existing code
def create_context_aware_quiz_agent(llm_provider: LLMProvider) -> ContextAwareQuizAgent:
    """Factory function to create ContextAwareQuizAgent."""
    return ContextAwareQuizAgent(llm_provider)