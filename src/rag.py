from langchain_community.vectorstores import Chroma
from langchain.schema import Document  # ‚Üê ƒê·∫¢M B·∫¢O C√ì IMPORT N√ÄY
from .fallback_llm import FallbackLLM, OfflineLLM
import json
import re
import traceback
class RAGManager:
    """
    Qu·∫£n l√Ω pipeline RAG: chunking, embedding, truy v·∫•n v√† t·∫°o quiz.
    Phi√™n b·∫£n n√†y c√≥ x·ª≠ l√Ω chu·ªói JSON tr·∫£ v·ªÅ t·ª´ LLM tƒ©nh h∆°n v√† h·ªó tr·ª£ k√Ω t·ª± to√°n h·ªçc.
    """
    def __init__(self, chunker, embedder, llm):
        self.chunker = chunker
        self.embedder = embedder
        self.llm = llm
        self.fallback_llm = FallbackLLM()
        self.offline_llm = OfflineLLM()
        self.retriever = None
        self.vector_store = None

    def enhanced_math_aware_chunking(self, text_content: str):
        """
        Chia vƒÉn b·∫£n th√†nh chunks v·ªõi vi·ªác b·∫£o v·ªá to√†n di·ªán c√°c bi·ªÉu th·ª©c to√°n h·ªçc v√† c·∫•u tr√∫c h·ªçc thu·∫≠t.
        """
        lines = text_content.split('\n')
        chunks = []
        current_chunk = ""
        current_topic = ""
        
        # Enhanced math patterns - bao ph·ªß nhi·ªÅu tr∆∞·ªùng h·ª£p h∆°n
        math_patterns = [
            # Basic operators v√† symbols
            r'.*?[=+\-*/^‚àö‚à´‚àë‚àè‚àà‚àâ‚äÜ‚äá‚à™‚à©‚àÖ‚Üí‚Üê‚Üî‚áí‚áî‚â†‚â§‚â•‚âà‚â°‚àº‚âÉ‚àù‚àû‚àÇ‚àá].*?',
            # Greek letters
            r'.*?[Œ±Œ≤Œ≥Œ¥ŒµŒ∂Œ∑Œ∏ŒπŒ∫ŒªŒºŒΩŒæŒøœÄœÅœÉœÑœÖœÜœáœàœâŒëŒíŒìŒîŒïŒñŒóŒòŒôŒöŒõŒúŒùŒûŒüŒ†Œ°Œ£Œ§Œ•Œ¶ŒßŒ®Œ©].*?',
            # Functions
            r'.*?\b(sin|cos|tan|log|ln|exp|det|tr|rank|dim|deg|gcd|lcm|max|min|sup|inf|lim)\s*\(.*?\).*?',
            # LaTeX expressions
            r'.*?\$.*?\$.*?',
            r'.*?\$\$.*?\$\$.*?',
            r'.*?\\begin\{.*?\}.*?\\end\{.*?\}.*?',
            r'.*?\\frac\{.*?\}\{.*?\}.*?',
            r'.*?\\sqrt\{.*?\}.*?',
            r'.*?\\[a-zA-Z]+\{.*?\}.*?',
            # Matrices v√† arrays
            r'.*?\[.*?=.*?\].*?',
            r'.*?\|.*?\|.*?',  # Determinants
            r'.*?det\s*\(.*?\).*?',
            # Numbers v√† equations
            r'.*?\d+\.\d+.*?=.*?',
            r'.*?[a-zA-Z]\s*[=‚âà‚â†]\s*\d+.*?',
            # Problem structures
            r'.*?\b(Problem|B√†i|C√¢u|V√≠ d·ª•|Example)\s*\d+.*?',
            r'.*?\b(ƒê·ªãnh l√Ω|Theorem|Lemma|Corollary).*?',
            r'.*?\b(Ch·ª©ng minh|Proof|Solution|Gi·∫£i).*?',
        ]
        
        # Academic structure patterns
        header_patterns = [
            r'^#+\s+.*?$',  # Markdown headers
            r'^\d+\.\s+.*?$',  # Numbered sections
            r'^[A-Z][A-Z\s]+$',  # ALL CAPS headers
            r'^\*\*.*?\*\*$',  # Bold headers
            r'^Ch∆∞∆°ng\s+\d+.*?$',  # Vietnamese chapters
            r'^B√†i\s+\d+.*?$',  # Vietnamese lessons
        ]
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
                
            # Detect headers and topics
            is_header = any(re.match(pattern, line) for pattern in header_patterns)
            if is_header:
                # Start new chunk for new topic
                if current_chunk.strip():
                    chunks.append({
                        'content': current_chunk.strip(),
                        'topic': current_topic,
                        'type': 'content'
                    })
                current_topic = line
                current_chunk = f"[TOPIC]{line}[/TOPIC]\n"
                continue
            
            # Detect math content
            is_math_line = any(re.search(pattern, line) for pattern in math_patterns)
            if is_math_line:
                line = f"[MATH]{line}[/MATH]"
            
            # Smart chunking based on content type
            estimated_chunk_size = len(current_chunk) + len(line)
            
            # Dynamic chunk size based on content
            if is_math_line:
                max_chunk_size = 1500  # Larger for math content
            elif current_topic and 'v√≠ d·ª•' in current_topic.lower():
                max_chunk_size = 2000  # Larger for examples
            else:
                max_chunk_size = 1000  # Standard size
            
            # Check if we should start new chunk
            should_split = False
            
            if estimated_chunk_size > max_chunk_size:
                should_split = True
            elif i < len(lines) - 1:
                # Look ahead for natural break points
                next_line = lines[i + 1].strip()
                if any(re.match(pattern, next_line) for pattern in header_patterns):
                    should_split = True
                elif next_line.startswith(('V√≠ d·ª•', 'Example', 'B√†i t·∫≠p', 'Exercise')):
                    should_split = True
            
            if should_split and current_chunk.strip():
                chunks.append({
                    'content': current_chunk.strip(),
                    'topic': current_topic,
                    'type': 'math' if '[MATH]' in current_chunk else 'content'
                })
                current_chunk = line + "\n"
            else:
                current_chunk += line + "\n"
        
        # Add final chunk
        if current_chunk.strip():
            chunks.append({
                'content': current_chunk.strip(),
                'topic': current_topic,
                'type': 'math' if '[MATH]' in current_chunk else 'content'
            })
        
        return chunks

    def math_aware_chunking(self, text_content: str):
        """
        Chia vƒÉn b·∫£n th√†nh chunks v·ªõi vi·ªác b·∫£o v·ªá c√°c bi·ªÉu th·ª©c to√°n h·ªçc.
        Deprecated: S·ª≠ d·ª•ng enhanced_math_aware_chunking thay th·∫ø.
        """
        enhanced_chunks = self.enhanced_math_aware_chunking(text_content)
        # Return simple list for backward compatibility
        return [chunk['content'] for chunk in enhanced_chunks]

    def setup_with_text(self, text_content: str):
        """
        Thi·∫øt l·∫≠p h·ªá th·ªëng RAG v·ªõi n·ªôi dung vƒÉn b·∫£n s·ª≠ d·ª•ng enhanced chunking.
        """
        # S·ª≠ d·ª•ng enhanced math-aware chunking
        enhanced_chunks = self.enhanced_math_aware_chunking(text_content)
        
        # Process chunks with metadata preservation
        documents = []
        for i, chunk_info in enumerate(enhanced_chunks):
            content = chunk_info['content']
            
            # Clean markers nh∆∞ng gi·ªØ nguy√™n c·∫•u tr√∫c
            clean_content = content.replace("[MATH]", "").replace("[/MATH]", "")
            clean_content = clean_content.replace("[TOPIC]", "").replace("[/TOPIC]", "")
            
            if clean_content.strip():
                # T·∫°o metadata phong ph√∫
                metadata = {
                    'chunk_id': i,
                    'topic': chunk_info['topic'],
                    'type': chunk_info['type'],
                    'has_math': '[MATH]' in content,
                    'has_topic': '[TOPIC]' in content,
                    'length': len(clean_content),
                    'position': i / len(enhanced_chunks)  # Relative position
                }
                
                # Add context from neighboring chunks
                if i > 0:
                    prev_chunk = enhanced_chunks[i-1]
                    metadata['prev_topic'] = prev_chunk['topic']
                    metadata['prev_type'] = prev_chunk['type']
                
                if i < len(enhanced_chunks) - 1:
                    next_chunk = enhanced_chunks[i+1]
                    metadata['next_topic'] = next_chunk['topic']
                    metadata['next_type'] = next_chunk['type']
                
                documents.append(Document(
                    page_content=clean_content.strip(),
                    metadata=metadata
                ))
        
        # X√¢y d·ª±ng vector store v·ªõi enhanced documents
        self.vector_store = Chroma.from_documents(
            documents=documents,
            embedding=self.embedder,
            persist_directory="./chroma_db"
        )
        
        self.retriever = self.vector_store.as_retriever(
            search_type="mmr",  # Maximum Marginal Relevance for diversity
            search_kwargs={
                "k": 5,
                "fetch_k": 10,
                "lambda_mult": 0.7  # Balance relevance vs diversity
            }
        )
        
        print(f"‚úÖ ƒê√£ setup RAG v·ªõi {len(documents)} enhanced chunks (c√≥ metadata)")
        return True

    def query(self, question: str) -> str:
        """
        Truy v·∫•n h·ªá th·ªëng RAG v·ªõi c√¢u h·ªèi.
        """
        try:
            if not self.retriever:
                return "L·ªói: Ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c x·ª≠ l√Ω. Vui l√≤ng t·∫£i l√™n t√†i li·ªáu tr∆∞·ªõc."
            
            # T√¨m ki·∫øm documents li√™n quan
            docs = self.retriever.invoke(question, config={"search_kwargs": {"k": 7}})
            
            if not docs:
                return "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu."
            
            # X·ª≠ l√Ω LaTeX trong context
            from .document_reader import DocumentReader
            doc_reader = DocumentReader()
            
            # ∆Øu ti√™n n·ªôi dung c√≥ to√°n h·ªçc
            context_parts = []
            math_indicators = ['=', '+', '-', 'Œª', 'Œ±', '‚Ñù', '‚ÑÇ', 'det(', '‚àà', '‚àâ', '‚äÜ']
            
            for doc in docs:
                processed_content = doc_reader.normalize_math_text(doc.page_content)
                
                # ƒê∆∞a n·ªôi dung to√°n h·ªçc l√™n ƒë·∫ßu
                if any(indicator in processed_content for indicator in math_indicators):
                    context_parts.insert(0, processed_content)
                else:
                    context_parts.append(processed_content)
            
            context = "\n".join(context_parts[:5])  # Gi·ªõi h·∫°n context
            
            # T·∫°o prompt
            prompt = f"""Quy t·∫Øc tr·∫£ l·ªùi:
- LU√îN s·ª≠ d·ª•ng k√Ω hi·ªáu Unicode: Œª, Œ±, Œ≤, ‚Ñù, ‚ÑÇ, ‚àà, ‚àâ, ‚äÜ, ‚äá
- KH√îNG s·ª≠ d·ª•ng LaTeX commands: \\lambda, \\mathbb{{R}}, \\alpha
- GI·ªÆ NGUY√äN c√¥ng th·ª©c to√°n h·ªçc trong d·∫•u ngo·∫∑c vu√¥ng: [Av = Œªv]
- Tr·∫£ l·ªùi ch√≠nh x√°c, chi ti·∫øt v√† d·ªÖ hi·ªÉu

V√≠ d·ª• ƒë√∫ng: "Eigenvalue Œª ‚àà ‚ÑÇ c·ªßa ma tr·∫≠n A ‚àà ‚Ñù^{{n√ón}}"
V√≠ d·ª• sai: "Eigenvalue \\lambda \\in \\mathbb{{C}} c·ªßa ma tr·∫≠n A"

Context t·ª´ t√†i li·ªáu:
{context}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi:"""

            # G·ªçi LLM v·ªõi fallback
            response = self._call_llm_with_fallback(prompt)
            
            # Post-process response ƒë·ªÉ ƒë·∫£m b·∫£o Unicode
            response = doc_reader.normalize_math_text(response)
            
            return response
            
        except Exception as e:
            print(f"‚ùå L·ªói trong query: {str(e)}")
            return "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i."

    def generate_quiz(self, num_questions: int = 5):
        """T·∫°o quiz t·ª´ documents v·ªõi x·ª≠ l√Ω LaTeX."""
        try:
            print(f"üéØ B·∫Øt ƒë·∫ßu t·∫°o quiz v·ªõi {num_questions} c√¢u h·ªèi...")
            
            if not self.retriever:
                error_msg = "L·ªói: Ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c x·ª≠ l√Ω. Vui l√≤ng t·∫£i l√™n t√†i li·ªáu tr∆∞·ªõc."
                print(f"‚ùå {error_msg}")
                return error_msg
                
            # L·∫•y nhi·ªÅu documents ƒë·ªÉ c√≥ ƒë·ªß n·ªôi dung
            print("üîç ƒêang t√¨m ki·∫øm n·ªôi dung t·ª´ t√†i li·ªáu...")
            all_docs = self.retriever.invoke("", config={"search_kwargs": {"k": 15}})
            
            if not all_docs:
                error_msg = "L·ªói: Kh√¥ng t√¨m th·∫•y n·ªôi dung ph√π h·ª£p ƒë·ªÉ t·∫°o quiz."
                print(f"‚ùå {error_msg}")
                return error_msg
            
            print(f"‚úÖ T√¨m th·∫•y {len(all_docs)} ƒëo·∫°n vƒÉn b·∫£n")
                
            # X·ª≠ l√Ω LaTeX trong documents
            from .document_reader import DocumentReader
            doc_reader = DocumentReader()
            
            processed_docs = []
            math_docs = []
            regular_docs = []
            
            print("üîÑ ƒêang x·ª≠ l√Ω v√† ph√¢n lo·∫°i n·ªôi dung...")
            
            # Ph√¢n lo·∫°i v√† x·ª≠ l√Ω documents
            for i, doc in enumerate(all_docs):
                try:
                    processed_content = doc_reader.normalize_math_text(doc.page_content)
                    
                    # T·∫°o document object ƒë∆°n gi·∫£n
                    class SimpleDoc:
                        def __init__(self, content, metadata=None):
                            self.page_content = content
                            self.metadata = metadata or {}
                    
                    processed_doc = SimpleDoc(
                        processed_content, 
                        doc.metadata if hasattr(doc, 'metadata') else {}
                    )
                    
                    # Ph√¢n lo·∫°i theo n·ªôi dung
                    math_indicators = ['=', '+', '-', 'Œª', 'Œ±', '‚Ñù', '‚ÑÇ', 'det(', '‚àà', '‚àâ', '‚äÜ']
                    
                    if any(indicator in processed_content for indicator in math_indicators):
                        math_docs.append(processed_doc)
                    else:
                        regular_docs.append(processed_doc)
                        
                except Exception as doc_error:
                    print(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω document {i+1}: {doc_error}")
                    continue
            
            print(f"üìä Ph√¢n lo·∫°i: {len(math_docs)} ƒëo·∫°n to√°n h·ªçc, {len(regular_docs)} ƒëo·∫°n th∆∞·ªùng")
            
            # C√¢n b·∫±ng content: 60% to√°n h·ªçc, 40% th√¥ng th∆∞·ªùng
            max_math = max(1, min(len(math_docs), int(num_questions * 0.6 * 2)))  # x2 v√¨ c·∫ßn nhi·ªÅu context
            max_regular = max(1, min(len(regular_docs), int(num_questions * 0.4 * 2)))
            
            selected_docs = math_docs[:max_math] + regular_docs[:max_regular]
            
            if not selected_docs:
                error_msg = "L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω n·ªôi dung t√†i li·ªáu. Vui l√≤ng th·ª≠ t√†i li·ªáu kh√°c."
                print(f"‚ùå {error_msg}")
                return error_msg
            
            print(f"‚úÖ Ch·ªçn {len(selected_docs)} ƒëo·∫°n ƒë·ªÉ t·∫°o quiz")
            
            # T·∫°o context - GI·ªöI H·∫†N CONTEXT ƒê·ªÇ TR√ÅNH QU√Å D√ÄI
            context_parts = []
            total_length = 0
            
            for doc in selected_docs:
                if total_length + len(doc.page_content) > 4000:  # Gi·ªõi h·∫°n 4K chars
                    break
                context_parts.append(doc.page_content)
                total_length += len(doc.page_content)
            
            context = "\n\n---\n\n".join(context_parts)
            
            print(f"üìù Context length: {len(context)} characters")
            
            # T·∫°o prompt ng·∫Øn g·ªçn h∆°n cho quiz generation
            quiz_prompt = f"""T·∫°o {min(num_questions, 3)} c√¢u h·ªèi tr·∫Øc nghi·ªám t·ª´ n·ªôi dung sau.

QUAN TR·ªåNG: CH·ªà tr·∫£ v·ªÅ JSON array, kh√¥ng c√≥ text kh√°c.

Format:
[{{"question": "C√¢u h·ªèi?", "choices": ["A. ...", "B. ...", "C. ...", "D. ..."], "correct_answer": 1}}]

N·ªôi dung:
{context[:2000]}...

JSON:"""

            print("ü§ñ ƒêang g·ªçi LLM ƒë·ªÉ t·∫°o quiz...")
            print(f"üìè Prompt length: {len(quiz_prompt)} characters")
            
            # G·ªçi LLM v·ªõi timeout ng·∫Øn h∆°n
            response = self._call_llm_with_fallback(quiz_prompt)
            
            if not response or response.strip() == "":
                error_msg = "L·ªói: LLM kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£. Vui l√≤ng th·ª≠ l·∫°i."
                print(f"‚ùå {error_msg}")
                return error_msg
            
            print(f"üìù K·∫øt qu·∫£ t·ª´ LLM ({len(response)} chars): {response[:300]}...")
            
            # X·ª≠ l√Ω v√† parse JSON
            try:
                # L√†m s·∫°ch response
                response = response.strip()
                
                # Lo·∫°i b·ªè markdown code blocks n·∫øu c√≥
                if '```json' in response:
                    start = response.find('```json') + 7
                    end = response.find('```', start)
                    if end != -1:
                        response = response[start:end].strip()
                elif '```' in response:
                    start = response.find('```') + 3
                    end = response.find('```', start)
                    if end != -1:
                        response = response[start:end].strip()
                
                # T√¨m JSON array
                start_idx = response.find('[')
                end_idx = response.rfind(']') + 1
                
                if start_idx == -1 or end_idx == 0:
                    print(f"‚ùå Kh√¥ng t√¨m th·∫•y JSON array trong response: {response}")
                    # Th·ª≠ t·∫°o JSON t·ª´ text n·∫øu c√≥ th·ªÉ
                    if "c√¢u h·ªèi" in response.lower():
                        return self._extract_quiz_from_text(response, num_questions)
                    raise ValueError("Kh√¥ng t√¨m th·∫•y JSON array trong response")
                
                json_str = response[start_idx:end_idx]
                print(f"üìù JSON ƒë∆∞·ª£c tr√≠ch xu·∫•t: {json_str[:500]}...")
                
                # Parse JSON
                quiz_data = json.loads(json_str)
                
                if not isinstance(quiz_data, list):
                    raise ValueError(f"JSON kh√¥ng ph·∫£i l√† array: {type(quiz_data)}")
                
                if len(quiz_data) == 0:
                    raise ValueError("Array JSON r·ªóng")
                
                print(f"‚úÖ Parse JSON th√†nh c√¥ng: {len(quiz_data)} c√¢u h·ªèi")
                
                # Validate t·ª´ng c√¢u h·ªèi
                validated_questions = []
                for i, q in enumerate(quiz_data):
                    try:
                        # Ki·ªÉm tra c√°c field b·∫Øt bu·ªôc
                        if not all(key in q for key in ['question', 'choices', 'correct_answer']):
                            print(f"‚ö†Ô∏è C√¢u h·ªèi {i+1} thi·∫øu field b·∫Øt bu·ªôc")
                            continue
                        
                        # Ki·ªÉm tra choices
                        if not isinstance(q['choices'], list) or len(q['choices']) != 4:
                            print(f"‚ö†Ô∏è C√¢u h·ªèi {i+1} kh√¥ng c√≥ ƒë√∫ng 4 l·ª±a ch·ªçn")
                            continue
                        
                        # Ki·ªÉm tra correct_answer
                        if not isinstance(q['correct_answer'], int) or q['correct_answer'] < 1 or q['correct_answer'] > 4:
                            print(f"‚ö†Ô∏è C√¢u h·ªèi {i+1} c√≥ correct_answer kh√¥ng h·ª£p l·ªá")
                            continue
                        
                        validated_questions.append(q)
                        
                    except Exception as validation_error:
                        print(f"‚ö†Ô∏è L·ªói validate c√¢u h·ªèi {i+1}: {validation_error}")
                        continue
                
                if len(validated_questions) == 0:
                    error_msg = "L·ªói: Kh√¥ng c√≥ c√¢u h·ªèi n√†o h·ª£p l·ªá sau khi validate."
                    print(f"‚ùå {error_msg}")
                    # Fallback: T·∫°o quiz template
                    return json.loads(self._generate_template_quiz())
                
                print(f"‚úÖ T·∫°o quiz th√†nh c√¥ng: {len(validated_questions)} c√¢u h·ªèi h·ª£p l·ªá")
                return validated_questions
                
            except json.JSONDecodeError as e:
                error_msg = f"L·ªói: Kh√¥ng th·ªÉ ph√¢n t√≠ch JSON t·ª´ AI. Chi ti·∫øt: {str(e)}"
                print(f"‚ùå {error_msg}")
                print(f"üìù Response g·ªëc: {response}")
                # Fallback: Th·ª≠ extract t·ª´ text
                try:
                    return self._extract_quiz_from_text(response, num_questions)
                except:
                    return json.loads(self._generate_template_quiz())
                
            except Exception as parse_error:
                error_msg = f"L·ªói: ƒê·ªãnh d·∫°ng quiz kh√¥ng ƒë√∫ng. Chi ti·∫øt: {str(parse_error)}"
                print(f"‚ùå {error_msg}")
                print(f"üìù Response g·ªëc: {response}")
                return json.loads(self._generate_template_quiz())
            
        except Exception as e:
            error_msg = f"L·ªói: H·ªá th·ªëng g·∫∑p s·ª± c·ªë. Chi ti·∫øt: {str(e)}"
            print(f"‚ùå L·ªói trong generate_quiz: {str(e)}")
            traceback.print_exc()
            return json.loads(self._generate_template_quiz())

    def _extract_quiz_from_text(self, text: str, num_questions: int):
        """
        Th·ª≠ extract quiz t·ª´ text khi JSON parsing fail.
        """
        try:
            print("üîÑ ƒêang th·ª≠ extract quiz t·ª´ plain text...")
            
            # Simple fallback: t·∫°o quiz t·ª´ context
            quiz = [
                {
                    "question": "D·ª±a tr√™n n·ªôi dung ƒë√£ h·ªçc, kh√°i ni·ªám n√†o sau ƒë√¢y l√† quan tr·ªçng nh·∫•t?",
                    "choices": [
                        "A. Kh√°i ni·ªám c∆° b·∫£n",
                        "B. Kh√°i ni·ªám n√¢ng cao", 
                        "C. Kh√°i ni·ªám ·ª©ng d·ª•ng",
                        "D. T·∫•t c·∫£ ƒë·ªÅu quan tr·ªçng"
                    ],
                    "correct_answer": 4
                },
                {
                    "question": "ƒê·ªÉ hi·ªÉu s√¢u h∆°n v·ªÅ ch·ªß ƒë·ªÅ n√†y, b·∫°n n√™n l√†m g√¨?",
                    "choices": [
                        "A. ƒê·ªçc th√™m t√†i li·ªáu",
                        "B. Th·ª±c h√†nh b√†i t·∫≠p",
                        "C. Th·∫£o lu·∫≠n v·ªõi b·∫°n b√®",
                        "D. C·∫£ ba ph∆∞∆°ng ph√°p tr√™n"
                    ],
                    "correct_answer": 4
                }
            ]
            
            return quiz[:num_questions]
            
        except Exception as e:
            print(f"‚ùå Extract t·ª´ text c≈©ng l·ªói: {e}")
            return json.loads(self._generate_template_quiz())
    
    def act_as_expert(self, question: str, chat_history: list = []) -> str:
        """
        Ho·∫°t ƒë·ªông nh∆∞ m·ªôt chuy√™n gia trong lƒ©nh v·ª±c t√†i li·ªáu.
        """
        try:
            if not self.retriever:
                return "L·ªói: Ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c x·ª≠ l√Ω. Vui l√≤ng t·∫£i l√™n t√†i li·ªáu tr∆∞·ªõc."
            
            # T√¨m ki·∫øm context
            docs = self.retriever.invoke(question, config={"search_kwargs": {"k": 5}})
            
            if not docs:
                return "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y."
            
            # X·ª≠ l√Ω LaTeX trong context
            from .document_reader import DocumentReader
            doc_reader = DocumentReader()
            
            context = "\n".join([doc_reader.normalize_math_text(doc.page_content) for doc in docs])
            
            # X√¢y d·ª±ng l·ªãch s·ª≠ chat
            history_text = ""
            if chat_history:
                recent_history = chat_history[-3:]  # Ch·ªâ l·∫•y 3 tin nh·∫Øn g·∫ßn nh·∫•t
                for msg in recent_history:
                    if msg.get('role') == 'user':
                        history_text += f"H·ªçc sinh: {msg.get('content', '')}\n"
                    elif msg.get('role') == 'assistant':
                        history_text += f"Chuy√™n gia: {msg.get('content', '')}\n"
            
            # T·∫°o prompt chuy√™n gia
            expert_prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia gi√†u kinh nghi·ªám trong lƒ©nh v·ª±c n√†y. H√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch chuy√™n nghi·ªáp, chi ti·∫øt v√† h·ªçc thu·∫≠t.

QUY T·∫ÆC:
- LU√îN s·ª≠ d·ª•ng k√Ω hi·ªáu Unicode: Œª, Œ±, Œ≤, ‚Ñù, ‚ÑÇ, ‚àà, ‚àâ, ‚äÜ
- KH√îNG s·ª≠ d·ª•ng LaTeX commands: \\lambda, \\mathbb{{R}}
- Gi·∫£i th√≠ch r√µ r√†ng, c√≥ v√≠ d·ª• c·ª• th·ªÉ
- S·ª≠ d·ª•ng thu·∫≠t ng·ªØ chuy√™n m√¥n ch√≠nh x√°c

{f"L·ªãch s·ª≠ tr√≤ chuy·ªán g·∫ßn ƒë√¢y:\\n{history_text}" if history_text else ""}

Context t·ª´ t√†i li·ªáu:
{context}

C√¢u h·ªèi c·ªßa h·ªçc sinh: {question}

Tr·∫£ l·ªùi chuy√™n gia:"""

            response = self._call_llm_with_fallback(expert_prompt)
            
            # Post-process response
            response = doc_reader.normalize_math_text(response)
            
            return response
            
        except Exception as e:
            print(f"‚ùå L·ªói trong act_as_expert: {str(e)}")
            return "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i."

    def suggest_research_topics(self, num_topics: int = 3) -> str:
        """
        ƒê·ªÅ xu·∫•t c√°c ch·ªß ƒë·ªÅ nghi√™n c·ª©u d·ª±a tr√™n n·ªôi dung t√†i li·ªáu.
        """
        try:
            if not self.retriever:
                return "L·ªói: Ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c x·ª≠ l√Ω. Vui l√≤ng t·∫£i l√™n t√†i li·ªáu tr∆∞·ªõc."
            
            # L·∫•y t·∫•t c·∫£ n·ªôi dung li√™n quan
            docs = self.retriever.invoke("", config={"search_kwargs": {"k": 10}})
            
            if not docs:
                return "Xin l·ªói, kh√¥ng th·ªÉ ƒë·ªÅ xu·∫•t ch·ªß ƒë·ªÅ nghi√™n c·ª©u v√¨ kh√¥ng t√¨m th·∫•y n·ªôi dung ph√π h·ª£p."
            
            # X·ª≠ l√Ω LaTeX trong context
            from .document_reader import DocumentReader
            doc_reader = DocumentReader()
            
            all_content = "\n".join([doc_reader.normalize_math_text(doc.page_content) for doc in docs])
            
            # T·∫°o prompt
            topics_prompt = f"""D·ª±a tr√™n n·ªôi dung t√†i li·ªáu, h√£y ƒë·ªÅ xu·∫•t {num_topics} ch·ªß ƒë·ªÅ nghi√™n c·ª©u th√∫ v·ªã v√† c√≥ t√≠nh th·ª±c ti·ªÖn.

QUY T·∫ÆC:
- LU√îN s·ª≠ d·ª•ng k√Ω hi·ªáu Unicode: Œª, Œ±, Œ≤, ‚Ñù, ‚ÑÇ, ‚àà, ‚àâ, ‚äÜ
- KH√îNG s·ª≠ d·ª•ng LaTeX commands
- M·ªói ch·ªß ƒë·ªÅ n√™n c√≥ m√¥ t·∫£ ng·∫Øn g·ªçn v·ªÅ t·∫°i sao n√≥ th√∫ v·ªã
- ∆Øu ti√™n c√°c ch·ªß ƒë·ªÅ c√≥ t√≠nh ·ª©ng d·ª•ng th·ª±c t·∫ø

N·ªôi dung t√†i li·ªáu:
{all_content[:3000]}

ƒê·ªÅ xu·∫•t {num_topics} ch·ªß ƒë·ªÅ nghi√™n c·ª©u:"""

            response = self._call_llm_with_fallback(topics_prompt)
            
            # Post-process response
            response = doc_reader.normalize_math_text(response)
            
            return response
            
        except Exception as e:
            print(f"‚ùå L·ªói trong suggest_research_topics: {str(e)}")
            return "ƒê√£ x·∫£y ra l·ªói khi ƒë·ªÅ xu·∫•t ch·ªß ƒë·ªÅ nghi√™n c·ª©u. Vui l√≤ng th·ª≠ l·∫°i."

    def _call_llm_with_fallback(self, prompt: str, **kwargs) -> str:
        """
        G·ªçi LLM v·ªõi h·ªá th·ªëng fallback 3 t·∫ßng.
        """
        try:
            # T·∫ßng 1: LLM ch√≠nh (OpenRouter)
            print("ü§ñ ƒêang g·ªçi OpenRouter LLM...")
            response = self.llm.invoke(prompt, **kwargs)
            
            print(f"üìù OpenRouter response length: {len(response) if response else 0}")
            print(f"üìù OpenRouter response preview: {response[:100] if response else 'EMPTY'}")
            
            # Ki·ªÉm tra n·∫øu response r·ªóng ho·∫∑c None
            if not response or response.strip() == "":
                print("‚ö†Ô∏è OpenRouter tr·∫£ v·ªÅ response r·ªóng, chuy·ªÉn sang fallback...")
                raise Exception("Empty response from OpenRouter")
            
            # Ki·ªÉm tra n·∫øu response cho th·∫•y l·ªói k·∫øt n·ªëi
            if any(error_text in response.lower() for error_text in [
                "kh√¥ng th·ªÉ k·∫øt n·ªëi", "connection error", "timeout", 
                "network error", "api error", "rate limit", "error"
            ]):
                print("‚ö†Ô∏è OpenRouter c√≥ v·∫•n ƒë·ªÅ, chuy·ªÉn sang fallback...")
                raise Exception(f"OpenRouter error: {response[:100]}")
            
            print("‚úÖ OpenRouter response th√†nh c√¥ng")
            return response
            
        except Exception as e:
            print(f"‚ùå OpenRouter LLM l·ªói: {str(e)}")
            
            try:
                # T·∫ßng 2: Fallback LLM
                print("üîÑ ƒêang th·ª≠ fallback LLM...")
                fallback_response = self.fallback_llm.invoke(prompt)
                
                if fallback_response and fallback_response.strip():
                    print("‚úÖ Fallback LLM th√†nh c√¥ng")
                    return fallback_response
                else:
                    print("‚ö†Ô∏è Fallback LLM tr·∫£ v·ªÅ r·ªóng")
                    raise Exception("Fallback LLM returned empty")
                    
            except Exception as e2:
                print(f"‚ùå Fallback LLM l·ªói: {str(e2)}")
                
                try:
                    # T·∫ßng 3: Offline LLM
                    print("üîÑ ƒêang th·ª≠ offline LLM...")
                    offline_response = self.offline_llm.invoke(prompt)
                    
                    if offline_response and offline_response.strip():
                        print("‚úÖ Offline LLM th√†nh c√¥ng")
                        return offline_response
                    else:
                        print("‚ö†Ô∏è Offline LLM tr·∫£ v·ªÅ r·ªóng")
                        raise Exception("Offline LLM returned empty")
                        
                except Exception as e3:
                    print(f"‚ùå Offline LLM l·ªói: {str(e3)}")
                    
                    # T·∫ßng 4: Hardcoded fallback cho quiz generation
                    if "t·∫°o" in prompt.lower() and "c√¢u h·ªèi" in prompt.lower():
                        print("üÜò T·∫•t c·∫£ LLM ƒë·ªÅu l·ªói, s·ª≠ d·ª•ng template quiz...")
                        return self._generate_template_quiz()
                    
                    return "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i."

    def _generate_template_quiz(self):
        """
        T·∫°o quiz template khi t·∫•t c·∫£ LLM ƒë·ªÅu l·ªói.
        """
        template_quiz = [
            {
                "question": "ƒê√¢y l√† c√¢u h·ªèi m·∫´u khi h·ªá th·ªëng g·∫∑p s·ª± c·ªë. B·∫°n c√≥ hi·ªÉu kh√¥ng?",
                "choices": [
                    "A. C√≥, t√¥i hi·ªÉu",
                    "B. Kh√¥ng, t√¥i kh√¥ng hi·ªÉu", 
                    "C. C·∫ßn gi·∫£i th√≠ch th√™m",
                    "D. T√¥i mu·ªën th·ª≠ l·∫°i"
                ],
                "correct_answer": 1
            },
            {
                "question": "H·ªá th·ªëng ƒëang g·∫∑p v·∫•n ƒë·ªÅ t·∫°m th·ªùi. B·∫°n mu·ªën l√†m g√¨?",
                "choices": [
                    "A. Th·ª≠ l·∫°i sau",
                    "B. Li√™n h·ªá h·ªó tr·ª£",
                    "C. S·ª≠ d·ª•ng ch·ª©c nƒÉng kh√°c", 
                    "D. Tho√°t kh·ªèi h·ªá th·ªëng"
                ],
                "correct_answer": 1
            }
        ]
        return json.dumps(template_quiz, ensure_ascii=False)
        
    def enhanced_query_with_context(self, question: str) -> str:
        """Advanced query v·ªõi preprocessing v√† context awareness"""
        try:
            # 1. Ph√¢n lo·∫°i lo·∫°i c√¢u h·ªèi
            question_type = "general"
            if any(word in question.lower() for word in ["to√°n", "math", "t√≠nh", "gi·∫£i", "ph∆∞∆°ng tr√¨nh"]):
                question_type = "math"
            elif any(word in question.lower() for word in ["v·∫≠t l√Ω", "physics", "l·ª±c", "ƒëi·ªán"]):
                question_type = "physics"
            elif any(word in question.lower() for word in ["h√≥a", "chemistry", "ph·∫£n ·ª©ng", "ch·∫•t"]):
                question_type = "chemistry"
            
            # 2. T√¨m ki·∫øm v·ªõi fallback ƒë∆°n gi·∫£n (kh√¥ng d√πng MMR v√¨ dependency)
            if hasattr(self, 'retriever') and self.retriever:
                docs = self.retriever.invoke(question, config={"search_kwargs": {"k": 5}})
                
                # 3. Filter theo lo·∫°i c√¢u h·ªèi n·∫øu c√≥ metadata
                relevant_docs = []
                for doc in docs:
                    if hasattr(doc, 'metadata') and doc.metadata:
                        doc_topic = doc.metadata.get('topic', '').lower()
                        if question_type == "math" and any(math_word in doc_topic for math_word in ["to√°n", "math", "equation"]):
                            relevant_docs.append(doc)
                        elif question_type in doc_topic:
                            relevant_docs.append(doc)
                        else:
                            relevant_docs.append(doc)  # Fallback
                    else:
                        relevant_docs.append(doc)
                
                # 4. T·∫°o context t·ª´ docs
                if relevant_docs:
                    context_parts = []
                    for i, doc in enumerate(relevant_docs[:3]):  # Top 3 docs
                        content = doc.page_content if hasattr(doc, 'page_content') else str(doc)
                        context_parts.append(f"[T√†i li·ªáu {i+1}]: {content}")
                    
                    context = "\n\n".join(context_parts)
                    
                    # 5. Enhanced prompt v·ªõi context
                    enhanced_prompt = f"""
D·ª±a tr√™n ng·ªØ c·∫£nh sau, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† chi ti·∫øt.

NG·ªÆ C·∫¢NH:
{context}

C√ÇUH·ªéI: {question}

H∆Ø·ªöNG D·∫™N:
- Lo·∫°i c√¢u h·ªèi: {question_type}
- Tr·∫£ l·ªùi d·ª±a tr√™n ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p
- N·∫øu c·∫ßn t√≠nh to√°n, hi·ªÉn th·ªã c√°c b∆∞·ªõc r√µ r√†ng
- N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, n√≥i r√µ c·∫ßn th√™m g√¨

TR·∫¢ L·ªúI:"""
                    
                    # 6. G·ªçi LLM v·ªõi enhanced prompt
                    return self.llm_client.generate_response(enhanced_prompt)
                else:
                    return "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi."
            
            # Fallback to basic query if no vector store
            return self.query(question)
            
        except Exception as e:
            print(f"Error in enhanced query: {e}")
            return self.query(question)  # Fallback to basic query